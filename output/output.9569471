Error: near line 1: attempt to write a readonly database
2020-03-24 14:34:57.557401: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/tamusc/Anaconda/3-5.0.0.1/lib:/software/lsf/9.1/linux2.6-glibc2.3-x86_64/lib
2020-03-24 14:34:57.557638: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/tamusc/Anaconda/3-5.0.0.1/lib:/software/lsf/9.1/linux2.6-glibc2.3-x86_64/lib
2020-03-24 14:34:57.557666: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-03-24 14:35:03.731383: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-24 14:35:03.761414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:20:00.0 name: Tesla K20m computeCapability: 3.5
coreClock: 0.7055GHz coreCount: 13 deviceMemorySize: 4.63GiB deviceMemoryBandwidth: 193.71GiB/s
2020-03-24 14:35:03.762389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: 
pciBusID: 0000:8b:00.0 name: Tesla K20m computeCapability: 3.5
coreClock: 0.7055GHz coreCount: 13 deviceMemorySize: 4.63GiB deviceMemoryBandwidth: 193.71GiB/s
2020-03-24 14:35:03.762600: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/tamusc/Anaconda/3-5.0.0.1/lib:/software/lsf/9.1/linux2.6-glibc2.3-x86_64/lib
2020-03-24 14:35:03.762769: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/tamusc/Anaconda/3-5.0.0.1/lib:/software/lsf/9.1/linux2.6-glibc2.3-x86_64/lib
2020-03-24 14:35:03.763260: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/tamusc/Anaconda/3-5.0.0.1/lib:/software/lsf/9.1/linux2.6-glibc2.3-x86_64/lib
2020-03-24 14:35:03.763450: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/tamusc/Anaconda/3-5.0.0.1/lib:/software/lsf/9.1/linux2.6-glibc2.3-x86_64/lib
2020-03-24 14:35:03.763616: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/tamusc/Anaconda/3-5.0.0.1/lib:/software/lsf/9.1/linux2.6-glibc2.3-x86_64/lib
2020-03-24 14:35:03.763778: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/tamusc/Anaconda/3-5.0.0.1/lib:/software/lsf/9.1/linux2.6-glibc2.3-x86_64/lib
2020-03-24 14:35:03.763947: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/tamusc/Anaconda/3-5.0.0.1/lib:/software/lsf/9.1/linux2.6-glibc2.3-x86_64/lib
2020-03-24 14:35:03.766622: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-03-24 14:35:03.777599: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2500100000 Hz
2020-03-24 14:35:03.778831: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560517c73420 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-24 14:35:03.778864: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-24 14:35:03.948716: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560517cd9560 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-24 14:35:03.948781: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K20m, Compute Capability 3.5
2020-03-24 14:35:03.948804: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla K20m, Compute Capability 3.5
2020-03-24 14:35:03.949266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-24 14:35:03.949293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      
Categories:  ['Cutting', 'NotCutting']
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 480, 640, 3)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 239, 319, 32) 864         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 239, 319, 32) 96          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 239, 319, 32) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 237, 317, 32) 9216        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 237, 317, 32) 96          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 237, 317, 32) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 237, 317, 64) 18432       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 237, 317, 64) 192         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 237, 317, 64) 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 118, 158, 64) 0           activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 118, 158, 80) 5120        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 118, 158, 80) 240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 118, 158, 80) 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 116, 156, 192 138240      activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 116, 156, 192 576         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 116, 156, 192 0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 57, 77, 192)  0           activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 57, 77, 64)   12288       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 57, 77, 64)   192         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 57, 77, 64)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 57, 77, 48)   9216        max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 57, 77, 96)   55296       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 57, 77, 48)   144         conv2d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 57, 77, 96)   288         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 57, 77, 48)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 57, 77, 96)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 57, 77, 192)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 57, 77, 64)   12288       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 57, 77, 64)   76800       activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 57, 77, 96)   82944       activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 57, 77, 32)   6144        average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 57, 77, 64)   192         conv2d_6[0][0]                   
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 57, 77, 64)   192         conv2d_8[0][0]                   
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 57, 77, 96)   288         conv2d_11[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 57, 77, 32)   96          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 57, 77, 64)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 57, 77, 64)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 57, 77, 96)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 57, 77, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
mixed0 (Concatenate)            (None, 57, 77, 256)  0           activation_6[0][0]               
                                                                 activation_8[0][0]               
                                                                 activation_11[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 57, 77, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 57, 77, 64)   192         conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 57, 77, 64)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 57, 77, 48)   12288       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 57, 77, 96)   55296       activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 57, 77, 48)   144         conv2d_14[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 57, 77, 96)   288         conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 57, 77, 48)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 57, 77, 96)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 57, 77, 256)  0           mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 57, 77, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 57, 77, 64)   76800       activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 57, 77, 96)   82944       activation_17[0][0]              
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 57, 77, 64)   16384       average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 57, 77, 64)   192         conv2d_13[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 57, 77, 64)   192         conv2d_15[0][0]                  
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 57, 77, 96)   288         conv2d_18[0][0]                  
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 57, 77, 64)   192         conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 57, 77, 64)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 57, 77, 64)   0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 57, 77, 96)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 57, 77, 64)   0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
mixed1 (Concatenate)            (None, 57, 77, 288)  0           activation_13[0][0]              
                                                                 activation_15[0][0]              
                                                                 activation_18[0][0]              
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 57, 77, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 57, 77, 64)   192         conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 57, 77, 64)   0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 57, 77, 48)   13824       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 57, 77, 96)   55296       activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 57, 77, 48)   144         conv2d_21[0][0]                  
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 57, 77, 96)   288         conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 57, 77, 48)   0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 57, 77, 96)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 57, 77, 288)  0           mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 57, 77, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 57, 77, 64)   76800       activation_21[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 57, 77, 96)   82944       activation_24[0][0]              
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 57, 77, 64)   18432       average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 57, 77, 64)   192         conv2d_20[0][0]                  
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 57, 77, 64)   192         conv2d_22[0][0]                  
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 57, 77, 96)   288         conv2d_25[0][0]                  
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 57, 77, 64)   192         conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 57, 77, 64)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 57, 77, 64)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 57, 77, 96)   0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 57, 77, 64)   0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
mixed2 (Concatenate)            (None, 57, 77, 288)  0           activation_20[0][0]              
                                                                 activation_22[0][0]              
                                                                 activation_25[0][0]              
                                                                 activation_26[0][0]              
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 57, 77, 64)   18432       mixed2[0][0]                     
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 57, 77, 64)   192         conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 57, 77, 64)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 57, 77, 96)   55296       activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 57, 77, 96)   288         conv2d_29[0][0]                  
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 57, 77, 96)   0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 28, 38, 384)  995328      mixed2[0][0]                     
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 28, 38, 96)   82944       activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 28, 38, 384)  1152        conv2d_27[0][0]                  
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 28, 38, 96)   288         conv2d_30[0][0]                  
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 28, 38, 384)  0           batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 28, 38, 96)   0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 28, 38, 288)  0           mixed2[0][0]                     
__________________________________________________________________________________________________
mixed3 (Concatenate)            (None, 28, 38, 768)  0           activation_27[0][0]              
                                                                 activation_30[0][0]              
                                                                 max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 28, 38, 128)  98304       mixed3[0][0]                     
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 28, 38, 128)  384         conv2d_35[0][0]                  
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 28, 38, 128)  0           batch_normalization_35[0][0]     
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 28, 38, 128)  114688      activation_35[0][0]              
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 28, 38, 128)  384         conv2d_36[0][0]                  
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 28, 38, 128)  0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 28, 38, 128)  98304       mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 28, 38, 128)  114688      activation_36[0][0]              
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 28, 38, 128)  384         conv2d_32[0][0]                  
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 28, 38, 128)  384         conv2d_37[0][0]                  
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 28, 38, 128)  0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 28, 38, 128)  0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 28, 38, 128)  114688      activation_32[0][0]              
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 28, 38, 128)  114688      activation_37[0][0]              
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 28, 38, 128)  384         conv2d_33[0][0]                  
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 28, 38, 128)  384         conv2d_38[0][0]                  
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 28, 38, 128)  0           batch_normalization_33[0][0]     
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 28, 38, 128)  0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 28, 38, 768)  0           mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 28, 38, 192)  147456      mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 28, 38, 192)  172032      activation_33[0][0]              
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 28, 38, 192)  172032      activation_38[0][0]              
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 28, 38, 192)  147456      average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 28, 38, 192)  576         conv2d_31[0][0]                  
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 28, 38, 192)  576         conv2d_34[0][0]                  
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 28, 38, 192)  576         conv2d_39[0][0]                  
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 28, 38, 192)  576         conv2d_40[0][0]                  
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 28, 38, 192)  0           batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 28, 38, 192)  0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 28, 38, 192)  0           batch_normalization_39[0][0]     
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 28, 38, 192)  0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
mixed4 (Concatenate)            (None, 28, 38, 768)  0           activation_31[0][0]              
                                                                 activation_34[0][0]              
                                                                 activation_39[0][0]              
                                                                 activation_40[0][0]              
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 28, 38, 160)  122880      mixed4[0][0]                     
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 28, 38, 160)  480         conv2d_45[0][0]                  
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 28, 38, 160)  0           batch_normalization_45[0][0]     
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 28, 38, 160)  179200      activation_45[0][0]              
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 28, 38, 160)  480         conv2d_46[0][0]                  
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 28, 38, 160)  0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 28, 38, 160)  122880      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 28, 38, 160)  179200      activation_46[0][0]              
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 28, 38, 160)  480         conv2d_42[0][0]                  
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 28, 38, 160)  480         conv2d_47[0][0]                  
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 28, 38, 160)  0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 28, 38, 160)  0           batch_normalization_47[0][0]     
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 28, 38, 160)  179200      activation_42[0][0]              
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 28, 38, 160)  179200      activation_47[0][0]              
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 28, 38, 160)  480         conv2d_43[0][0]                  
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 28, 38, 160)  480         conv2d_48[0][0]                  
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 28, 38, 160)  0           batch_normalization_43[0][0]     
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 28, 38, 160)  0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 28, 38, 768)  0           mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 28, 38, 192)  147456      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 28, 38, 192)  215040      activation_43[0][0]              
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 28, 38, 192)  215040      activation_48[0][0]              
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 28, 38, 192)  147456      average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 28, 38, 192)  576         conv2d_41[0][0]                  
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 28, 38, 192)  576         conv2d_44[0][0]                  
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 28, 38, 192)  576         conv2d_49[0][0]                  
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 28, 38, 192)  576         conv2d_50[0][0]                  
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 28, 38, 192)  0           batch_normalization_41[0][0]     
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 28, 38, 192)  0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 28, 38, 192)  0           batch_normalization_49[0][0]     
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 28, 38, 192)  0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
mixed5 (Concatenate)            (None, 28, 38, 768)  0           activation_41[0][0]              
                                                                 activation_44[0][0]              
                                                                 activation_49[0][0]              
                                                                 activation_50[0][0]              
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 28, 38, 160)  122880      mixed5[0][0]                     
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 28, 38, 160)  480         conv2d_55[0][0]                  
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 28, 38, 160)  0           batch_normalization_55[0][0]     
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 28, 38, 160)  179200      activation_55[0][0]              
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 28, 38, 160)  480         conv2d_56[0][0]                  
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 28, 38, 160)  0           batch_normalization_56[0][0]     
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 28, 38, 160)  122880      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 28, 38, 160)  179200      activation_56[0][0]              
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 28, 38, 160)  480         conv2d_52[0][0]                  
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 28, 38, 160)  480         conv2d_57[0][0]                  
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 28, 38, 160)  0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 28, 38, 160)  0           batch_normalization_57[0][0]     
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 28, 38, 160)  179200      activation_52[0][0]              
__________________________________________________________________________________________________
conv2d_58 (Conv2D)              (None, 28, 38, 160)  179200      activation_57[0][0]              
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 28, 38, 160)  480         conv2d_53[0][0]                  
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 28, 38, 160)  480         conv2d_58[0][0]                  
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 28, 38, 160)  0           batch_normalization_53[0][0]     
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 28, 38, 160)  0           batch_normalization_58[0][0]     
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 28, 38, 768)  0           mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 28, 38, 192)  147456      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 28, 38, 192)  215040      activation_53[0][0]              
__________________________________________________________________________________________________
conv2d_59 (Conv2D)              (None, 28, 38, 192)  215040      activation_58[0][0]              
__________________________________________________________________________________________________
conv2d_60 (Conv2D)              (None, 28, 38, 192)  147456      average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 28, 38, 192)  576         conv2d_51[0][0]                  
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 28, 38, 192)  576         conv2d_54[0][0]                  
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 28, 38, 192)  576         conv2d_59[0][0]                  
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 28, 38, 192)  576         conv2d_60[0][0]                  
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 28, 38, 192)  0           batch_normalization_51[0][0]     
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 28, 38, 192)  0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 28, 38, 192)  0           batch_normalization_59[0][0]     
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 28, 38, 192)  0           batch_normalization_60[0][0]     
__________________________________________________________________________________________________
mixed6 (Concatenate)            (None, 28, 38, 768)  0           activation_51[0][0]              
                                                                 activation_54[0][0]              
                                                                 activation_59[0][0]              
                                                                 activation_60[0][0]              
__________________________________________________________________________________________________
conv2d_65 (Conv2D)              (None, 28, 38, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
batch_normalization_65 (BatchNo (None, 28, 38, 192)  576         conv2d_65[0][0]                  
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 28, 38, 192)  0           batch_normalization_65[0][0]     
__________________________________________________________________________________________________
conv2d_66 (Conv2D)              (None, 28, 38, 192)  258048      activation_65[0][0]              
__________________________________________________________________________________________________
batch_normalization_66 (BatchNo (None, 28, 38, 192)  576         conv2d_66[0][0]                  
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 28, 38, 192)  0           batch_normalization_66[0][0]     
__________________________________________________________________________________________________
conv2d_62 (Conv2D)              (None, 28, 38, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_67 (Conv2D)              (None, 28, 38, 192)  258048      activation_66[0][0]              
__________________________________________________________________________________________________
batch_normalization_62 (BatchNo (None, 28, 38, 192)  576         conv2d_62[0][0]                  
__________________________________________________________________________________________________
batch_normalization_67 (BatchNo (None, 28, 38, 192)  576         conv2d_67[0][0]                  
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 28, 38, 192)  0           batch_normalization_62[0][0]     
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 28, 38, 192)  0           batch_normalization_67[0][0]     
__________________________________________________________________________________________________
conv2d_63 (Conv2D)              (None, 28, 38, 192)  258048      activation_62[0][0]              
__________________________________________________________________________________________________
conv2d_68 (Conv2D)              (None, 28, 38, 192)  258048      activation_67[0][0]              
__________________________________________________________________________________________________
batch_normalization_63 (BatchNo (None, 28, 38, 192)  576         conv2d_63[0][0]                  
__________________________________________________________________________________________________
batch_normalization_68 (BatchNo (None, 28, 38, 192)  576         conv2d_68[0][0]                  
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 28, 38, 192)  0           batch_normalization_63[0][0]     
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 28, 38, 192)  0           batch_normalization_68[0][0]     
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 28, 38, 768)  0           mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_61 (Conv2D)              (None, 28, 38, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_64 (Conv2D)              (None, 28, 38, 192)  258048      activation_63[0][0]              
__________________________________________________________________________________________________
conv2d_69 (Conv2D)              (None, 28, 38, 192)  258048      activation_68[0][0]              
__________________________________________________________________________________________________
conv2d_70 (Conv2D)              (None, 28, 38, 192)  147456      average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 28, 38, 192)  576         conv2d_61[0][0]                  
__________________________________________________________________________________________________
batch_normalization_64 (BatchNo (None, 28, 38, 192)  576         conv2d_64[0][0]                  
__________________________________________________________________________________________________
batch_normalization_69 (BatchNo (None, 28, 38, 192)  576         conv2d_69[0][0]                  
__________________________________________________________________________________________________
batch_normalization_70 (BatchNo (None, 28, 38, 192)  576         conv2d_70[0][0]                  
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 28, 38, 192)  0           batch_normalization_61[0][0]     
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 28, 38, 192)  0           batch_normalization_64[0][0]     
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 28, 38, 192)  0           batch_normalization_69[0][0]     
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 28, 38, 192)  0           batch_normalization_70[0][0]     
__________________________________________________________________________________________________
mixed7 (Concatenate)            (None, 28, 38, 768)  0           activation_61[0][0]              
                                                                 activation_64[0][0]              
                                                                 activation_69[0][0]              
                                                                 activation_70[0][0]              
__________________________________________________________________________________________________
conv2d_73 (Conv2D)              (None, 28, 38, 192)  147456      mixed7[0][0]                     
__________________________________________________________________________________________________
batch_normalization_73 (BatchNo (None, 28, 38, 192)  576         conv2d_73[0][0]                  
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 28, 38, 192)  0           batch_normalization_73[0][0]     
__________________________________________________________________________________________________
conv2d_74 (Conv2D)              (None, 28, 38, 192)  258048      activation_73[0][0]              
__________________________________________________________________________________________________
batch_normalization_74 (BatchNo (None, 28, 38, 192)  576         conv2d_74[0][0]                  
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 28, 38, 192)  0           batch_normalization_74[0][0]     
__________________________________________________________________________________________________
conv2d_71 (Conv2D)              (None, 28, 38, 192)  147456      mixed7[0][0]                     
__________________________________________________________________________________________________
conv2d_75 (Conv2D)              (None, 28, 38, 192)  258048      activation_74[0][0]              
__________________________________________________________________________________________________
batch_normalization_71 (BatchNo (None, 28, 38, 192)  576         conv2d_71[0][0]                  
__________________________________________________________________________________________________
batch_normalization_75 (BatchNo (None, 28, 38, 192)  576         conv2d_75[0][0]                  
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 28, 38, 192)  0           batch_normalization_71[0][0]     
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 28, 38, 192)  0           batch_normalization_75[0][0]     
__________________________________________________________________________________________________
conv2d_72 (Conv2D)              (None, 13, 18, 320)  552960      activation_71[0][0]              
__________________________________________________________________________________________________
conv2d_76 (Conv2D)              (None, 13, 18, 192)  331776      activation_75[0][0]              
__________________________________________________________________________________________________
batch_normalization_72 (BatchNo (None, 13, 18, 320)  960         conv2d_72[0][0]                  
__________________________________________________________________________________________________
batch_normalization_76 (BatchNo (None, 13, 18, 192)  576         conv2d_76[0][0]                  
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 13, 18, 320)  0           batch_normalization_72[0][0]     
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 13, 18, 192)  0           batch_normalization_76[0][0]     
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 13, 18, 768)  0           mixed7[0][0]                     
__________________________________________________________________________________________________
mixed8 (Concatenate)            (None, 13, 18, 1280) 0           activation_72[0][0]              
                                                                 activation_76[0][0]              
                                                                 max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
conv2d_81 (Conv2D)              (None, 13, 18, 448)  573440      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_81 (BatchNo (None, 13, 18, 448)  1344        conv2d_81[0][0]                  
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 13, 18, 448)  0           batch_normalization_81[0][0]     
__________________________________________________________________________________________________
conv2d_78 (Conv2D)              (None, 13, 18, 384)  491520      mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_82 (Conv2D)              (None, 13, 18, 384)  1548288     activation_81[0][0]              
__________________________________________________________________________________________________
batch_normalization_78 (BatchNo (None, 13, 18, 384)  1152        conv2d_78[0][0]                  
__________________________________________________________________________________________________
batch_normalization_82 (BatchNo (None, 13, 18, 384)  1152        conv2d_82[0][0]                  
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 13, 18, 384)  0           batch_normalization_78[0][0]     
__________________________________________________________________________________________________
activation_82 (Activation)      (None, 13, 18, 384)  0           batch_normalization_82[0][0]     
__________________________________________________________________________________________________
conv2d_79 (Conv2D)              (None, 13, 18, 384)  442368      activation_78[0][0]              
__________________________________________________________________________________________________
conv2d_80 (Conv2D)              (None, 13, 18, 384)  442368      activation_78[0][0]              
__________________________________________________________________________________________________
conv2d_83 (Conv2D)              (None, 13, 18, 384)  442368      activation_82[0][0]              
__________________________________________________________________________________________________
conv2d_84 (Conv2D)              (None, 13, 18, 384)  442368      activation_82[0][0]              
__________________________________________________________________________________________________
average_pooling2d_8 (AveragePoo (None, 13, 18, 1280) 0           mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_77 (Conv2D)              (None, 13, 18, 320)  409600      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_79 (BatchNo (None, 13, 18, 384)  1152        conv2d_79[0][0]                  
__________________________________________________________________________________________________
batch_normalization_80 (BatchNo (None, 13, 18, 384)  1152        conv2d_80[0][0]                  
__________________________________________________________________________________________________
batch_normalization_83 (BatchNo (None, 13, 18, 384)  1152        conv2d_83[0][0]                  
__________________________________________________________________________________________________
batch_normalization_84 (BatchNo (None, 13, 18, 384)  1152        conv2d_84[0][0]                  
__________________________________________________________________________________________________
conv2d_85 (Conv2D)              (None, 13, 18, 192)  245760      average_pooling2d_8[0][0]        
__________________________________________________________________________________________________
batch_normalization_77 (BatchNo (None, 13, 18, 320)  960         conv2d_77[0][0]                  
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 13, 18, 384)  0           batch_normalization_79[0][0]     
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 13, 18, 384)  0           batch_normalization_80[0][0]     
__________________________________________________________________________________________________
activation_83 (Activation)      (None, 13, 18, 384)  0           batch_normalization_83[0][0]     
__________________________________________________________________________________________________
activation_84 (Activation)      (None, 13, 18, 384)  0           batch_normalization_84[0][0]     
__________________________________________________________________________________________________
batch_normalization_85 (BatchNo (None, 13, 18, 192)  576         conv2d_85[0][0]                  
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 13, 18, 320)  0           batch_normalization_77[0][0]     
__________________________________________________________________________________________________
mixed9_0 (Concatenate)          (None, 13, 18, 768)  0           activation_79[0][0]              
                                                                 activation_80[0][0]              
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 13, 18, 768)  0           activation_83[0][0]              
                                                                 activation_84[0][0]              
__________________________________________________________________________________________________
activation_85 (Activation)      (None, 13, 18, 192)  0           batch_normalization_85[0][0]     
__________________________________________________________________________________________________
mixed9 (Concatenate)            (None, 13, 18, 2048) 0           activation_77[0][0]              
                                                                 mixed9_0[0][0]                   
                                                                 concatenate_1[0][0]              
                                                                 activation_85[0][0]              
__________________________________________________________________________________________________
conv2d_90 (Conv2D)              (None, 13, 18, 448)  917504      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_90 (BatchNo (None, 13, 18, 448)  1344        conv2d_90[0][0]                  
__________________________________________________________________________________________________
activation_90 (Activation)      (None, 13, 18, 448)  0           batch_normalization_90[0][0]     
__________________________________________________________________________________________________
conv2d_87 (Conv2D)              (None, 13, 18, 384)  786432      mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_91 (Conv2D)              (None, 13, 18, 384)  1548288     activation_90[0][0]              
__________________________________________________________________________________________________
batch_normalization_87 (BatchNo (None, 13, 18, 384)  1152        conv2d_87[0][0]                  
__________________________________________________________________________________________________
batch_normalization_91 (BatchNo (None, 13, 18, 384)  1152        conv2d_91[0][0]                  
__________________________________________________________________________________________________
activation_87 (Activation)      (None, 13, 18, 384)  0           batch_normalization_87[0][0]     
__________________________________________________________________________________________________
activation_91 (Activation)      (None, 13, 18, 384)  0           batch_normalization_91[0][0]     
__________________________________________________________________________________________________
conv2d_88 (Conv2D)              (None, 13, 18, 384)  442368      activation_87[0][0]              
__________________________________________________________________________________________________
conv2d_89 (Conv2D)              (None, 13, 18, 384)  442368      activation_87[0][0]              
__________________________________________________________________________________________________
conv2d_92 (Conv2D)              (None, 13, 18, 384)  442368      activation_91[0][0]              
__________________________________________________________________________________________________
conv2d_93 (Conv2D)              (None, 13, 18, 384)  442368      activation_91[0][0]              
__________________________________________________________________________________________________
average_pooling2d_9 (AveragePoo (None, 13, 18, 2048) 0           mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_86 (Conv2D)              (None, 13, 18, 320)  655360      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_88 (BatchNo (None, 13, 18, 384)  1152        conv2d_88[0][0]                  
__________________________________________________________________________________________________
batch_normalization_89 (BatchNo (None, 13, 18, 384)  1152        conv2d_89[0][0]                  
__________________________________________________________________________________________________
batch_normalization_92 (BatchNo (None, 13, 18, 384)  1152        conv2d_92[0][0]                  
__________________________________________________________________________________________________
batch_normalization_93 (BatchNo (None, 13, 18, 384)  1152        conv2d_93[0][0]                  
__________________________________________________________________________________________________
conv2d_94 (Conv2D)              (None, 13, 18, 192)  393216      average_pooling2d_9[0][0]        
__________________________________________________________________________________________________
batch_normalization_86 (BatchNo (None, 13, 18, 320)  960         conv2d_86[0][0]                  
__________________________________________________________________________________________________
activation_88 (Activation)      (None, 13, 18, 384)  0           batch_normalization_88[0][0]     
__________________________________________________________________________________________________
activation_89 (Activation)      (None, 13, 18, 384)  0           batch_normalization_89[0][0]     
__________________________________________________________________________________________________
activation_92 (Activation)      (None, 13, 18, 384)  0           batch_normalization_92[0][0]     
__________________________________________________________________________________________________
activation_93 (Activation)      (None, 13, 18, 384)  0           batch_normalization_93[0][0]     
__________________________________________________________________________________________________
batch_normalization_94 (BatchNo (None, 13, 18, 192)  576         conv2d_94[0][0]                  
__________________________________________________________________________________________________
activation_86 (Activation)      (None, 13, 18, 320)  0           batch_normalization_86[0][0]     
__________________________________________________________________________________________________
mixed9_1 (Concatenate)          (None, 13, 18, 768)  0           activation_88[0][0]              
                                                                 activation_89[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 18, 768)  0           activation_92[0][0]              
                                                                 activation_93[0][0]              
__________________________________________________________________________________________________
activation_94 (Activation)      (None, 13, 18, 192)  0           batch_normalization_94[0][0]     
__________________________________________________________________________________________________
mixed10 (Concatenate)           (None, 13, 18, 2048) 0           activation_86[0][0]              
                                                                 mixed9_1[0][0]                   
                                                                 concatenate_2[0][0]              
                                                                 activation_94[0][0]              
__________________________________________________________________________________________________
avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2048)         0           avg_pool[0][0]                   
__________________________________________________________________________________________________
preprediction (Dense)           (None, 2)            4098        dropout_1[0][0]                  
__________________________________________________________________________________________________
prediction (Activation)         (None, 2)            0           preprediction[0][0]              
==================================================================================================
Total params: 21,806,882
Trainable params: 4,098
Non-trainable params: 21,802,784
__________________________________________________________________________________________________
None
Loading images...
Loaded all training images!
Loaded all validation images!
Loaded all testing images!
Successfully loaded data!
(2966, 480, 640, 3) (989, 480, 640, 3) (990, 480, 640, 3)
(2966, 2) (989, 2) (990, 2)
Epoch 1/10

 1/92 [..............................] - ETA: 11:16 - loss: 0.7151 - accuracy: 0.5938 - top_k_categorical_accuracy: 1.0000
 2/92 [..............................] - ETA: 8:23 - loss: 1.1272 - accuracy: 0.5312 - top_k_categorical_accuracy: 1.0000 
 3/92 [..............................] - ETA: 7:29 - loss: 0.9995 - accuracy: 0.5312 - top_k_categorical_accuracy: 1.0000
 4/92 [>.............................] - ETA: 6:57 - loss: 0.9220 - accuracy: 0.5625 - top_k_categorical_accuracy: 1.0000
 5/92 [>.............................] - ETA: 6:35 - loss: 0.8619 - accuracy: 0.5875 - top_k_categorical_accuracy: 1.0000
 6/92 [>.............................] - ETA: 6:19 - loss: 0.8097 - accuracy: 0.6250 - top_k_categorical_accuracy: 1.0000
 7/92 [=>............................] - ETA: 6:07 - loss: 0.7889 - accuracy: 0.6250 - top_k_categorical_accuracy: 1.0000
 8/92 [=>............................] - ETA: 5:57 - loss: 0.7607 - accuracy: 0.6328 - top_k_categorical_accuracy: 1.0000
 9/92 [=>............................] - ETA: 5:47 - loss: 0.7380 - accuracy: 0.6528 - top_k_categorical_accuracy: 1.0000
10/92 [==>...........................] - ETA: 5:39 - loss: 0.7235 - accuracy: 0.6531 - top_k_categorical_accuracy: 1.0000
11/92 [==>...........................] - ETA: 5:31 - loss: 0.7174 - accuracy: 0.6534 - top_k_categorical_accuracy: 1.0000
12/92 [==>...........................] - ETA: 5:24 - loss: 0.7176 - accuracy: 0.6432 - top_k_categorical_accuracy: 1.0000
13/92 [===>..........................] - ETA: 5:19 - loss: 0.7022 - accuracy: 0.6514 - top_k_categorical_accuracy: 1.0000
14/92 [===>..........................] - ETA: 5:13 - loss: 0.6927 - accuracy: 0.6540 - top_k_categorical_accuracy: 1.0000
15/92 [===>..........................] - ETA: 5:08 - loss: 0.6799 - accuracy: 0.6667 - top_k_categorical_accuracy: 1.0000
16/92 [====>.........................] - ETA: 5:03 - loss: 0.6713 - accuracy: 0.6719 - top_k_categorical_accuracy: 1.0000
17/92 [====>.........................] - ETA: 4:58 - loss: 0.6602 - accuracy: 0.6783 - top_k_categorical_accuracy: 1.0000
18/92 [====>.........................] - ETA: 4:53 - loss: 0.6547 - accuracy: 0.6753 - top_k_categorical_accuracy: 1.0000
19/92 [=====>........................] - ETA: 4:49 - loss: 0.6416 - accuracy: 0.6776 - top_k_categorical_accuracy: 1.0000
20/92 [=====>........................] - ETA: 4:44 - loss: 0.6359 - accuracy: 0.6797 - top_k_categorical_accuracy: 1.0000
21/92 [=====>........................] - ETA: 4:40 - loss: 0.6251 - accuracy: 0.6860 - top_k_categorical_accuracy: 1.0000
22/92 [======>.......................] - ETA: 4:36 - loss: 0.6183 - accuracy: 0.6932 - top_k_categorical_accuracy: 1.0000
23/92 [======>.......................] - ETA: 4:28 - loss: 0.6102 - accuracy: 0.6983 - top_k_categorical_accuracy: 1.0000
24/92 [======>.......................] - ETA: 4:24 - loss: 0.6016 - accuracy: 0.7071 - top_k_categorical_accuracy: 1.0000
25/92 [=======>......................] - ETA: 4:20 - loss: 0.5949 - accuracy: 0.7127 - top_k_categorical_accuracy: 1.0000
26/92 [=======>......................] - ETA: 4:16 - loss: 0.5872 - accuracy: 0.7178 - top_k_categorical_accuracy: 1.0000
27/92 [=======>......................] - ETA: 4:12 - loss: 0.5860 - accuracy: 0.7131 - top_k_categorical_accuracy: 1.0000
28/92 [========>.....................] - ETA: 4:08 - loss: 0.5791 - accuracy: 0.7201 - top_k_categorical_accuracy: 1.0000
29/92 [========>.....................] - ETA: 4:04 - loss: 0.5782 - accuracy: 0.7200 - top_k_categorical_accuracy: 1.0000
30/92 [========>.....................] - ETA: 4:00 - loss: 0.5745 - accuracy: 0.7189 - top_k_categorical_accuracy: 1.0000
31/92 [=========>....................] - ETA: 3:56 - loss: 0.5717 - accuracy: 0.7220 - top_k_categorical_accuracy: 1.0000
32/92 [=========>....................] - ETA: 3:52 - loss: 0.5646 - accuracy: 0.7258 - top_k_categorical_accuracy: 1.0000
33/92 [=========>....................] - ETA: 3:48 - loss: 0.5554 - accuracy: 0.7342 - top_k_categorical_accuracy: 1.0000
34/92 [==========>...................] - ETA: 3:44 - loss: 0.5472 - accuracy: 0.7412 - top_k_categorical_accuracy: 1.0000
35/92 [==========>...................] - ETA: 3:40 - loss: 0.5412 - accuracy: 0.7459 - top_k_categorical_accuracy: 1.0000
36/92 [==========>...................] - ETA: 3:37 - loss: 0.5361 - accuracy: 0.7513 - top_k_categorical_accuracy: 1.0000
37/92 [==========>...................] - ETA: 3:33 - loss: 0.5297 - accuracy: 0.7555 - top_k_categorical_accuracy: 1.0000
38/92 [===========>..................] - ETA: 3:29 - loss: 0.5240 - accuracy: 0.7595 - top_k_categorical_accuracy: 1.0000
39/92 [===========>..................] - ETA: 3:25 - loss: 0.5181 - accuracy: 0.7633 - top_k_categorical_accuracy: 1.0000
40/92 [===========>..................] - ETA: 3:21 - loss: 0.5130 - accuracy: 0.7677 - top_k_categorical_accuracy: 1.0000
41/92 [============>.................] - ETA: 3:17 - loss: 0.5115 - accuracy: 0.7650 - top_k_categorical_accuracy: 1.0000
42/92 [============>.................] - ETA: 3:13 - loss: 0.5060 - accuracy: 0.7691 - top_k_categorical_accuracy: 1.0000
43/92 [============>.................] - ETA: 3:09 - loss: 0.5003 - accuracy: 0.7731 - top_k_categorical_accuracy: 1.0000
44/92 [=============>................] - ETA: 3:05 - loss: 0.4952 - accuracy: 0.7768 - top_k_categorical_accuracy: 1.0000
45/92 [=============>................] - ETA: 3:01 - loss: 0.4907 - accuracy: 0.7797 - top_k_categorical_accuracy: 1.0000
46/92 [=============>................] - ETA: 2:58 - loss: 0.4859 - accuracy: 0.7832 - top_k_categorical_accuracy: 1.0000
47/92 [==============>...............] - ETA: 2:54 - loss: 0.4825 - accuracy: 0.7851 - top_k_categorical_accuracy: 1.0000
48/92 [==============>...............] - ETA: 2:50 - loss: 0.4835 - accuracy: 0.7837 - top_k_categorical_accuracy: 1.0000
49/92 [==============>...............] - ETA: 2:46 - loss: 0.4793 - accuracy: 0.7869 - top_k_categorical_accuracy: 1.0000
50/92 [===============>..............] - ETA: 2:42 - loss: 0.4760 - accuracy: 0.7893 - top_k_categorical_accuracy: 1.0000
51/92 [===============>..............] - ETA: 2:38 - loss: 0.4731 - accuracy: 0.7922 - top_k_categorical_accuracy: 1.0000
52/92 [===============>..............] - ETA: 2:34 - loss: 0.4684 - accuracy: 0.7956 - top_k_categorical_accuracy: 1.0000
53/92 [================>.............] - ETA: 2:30 - loss: 0.4662 - accuracy: 0.7977 - top_k_categorical_accuracy: 1.0000
54/92 [================>.............] - ETA: 2:27 - loss: 0.4618 - accuracy: 0.8009 - top_k_categorical_accuracy: 1.0000
55/92 [================>.............] - ETA: 2:23 - loss: 0.4572 - accuracy: 0.8046 - top_k_categorical_accuracy: 1.0000
56/92 [=================>............] - ETA: 2:19 - loss: 0.4538 - accuracy: 0.8064 - top_k_categorical_accuracy: 1.0000
57/92 [=================>............] - ETA: 2:15 - loss: 0.4490 - accuracy: 0.8093 - top_k_categorical_accuracy: 1.0000
58/92 [=================>............] - ETA: 2:11 - loss: 0.4454 - accuracy: 0.8115 - top_k_categorical_accuracy: 1.0000
59/92 [==================>...........] - ETA: 2:08 - loss: 0.4430 - accuracy: 0.8136 - top_k_categorical_accuracy: 1.0000
60/92 [==================>...........] - ETA: 2:04 - loss: 0.4395 - accuracy: 0.8157 - top_k_categorical_accuracy: 1.0000
61/92 [==================>...........] - ETA: 2:00 - loss: 0.4380 - accuracy: 0.8162 - top_k_categorical_accuracy: 1.0000
62/92 [===================>..........] - ETA: 1:56 - loss: 0.4357 - accuracy: 0.8181 - top_k_categorical_accuracy: 1.0000
63/92 [===================>..........] - ETA: 1:53 - loss: 0.4337 - accuracy: 0.8185 - top_k_categorical_accuracy: 1.0000
64/92 [===================>..........] - ETA: 1:50 - loss: 0.4310 - accuracy: 0.8194 - top_k_categorical_accuracy: 1.0000
65/92 [====================>.........] - ETA: 1:46 - loss: 0.4267 - accuracy: 0.8222 - top_k_categorical_accuracy: 1.0000
66/92 [====================>.........] - ETA: 1:43 - loss: 0.4244 - accuracy: 0.8240 - top_k_categorical_accuracy: 1.0000
67/92 [====================>.........] - ETA: 1:39 - loss: 0.4252 - accuracy: 0.8247 - top_k_categorical_accuracy: 1.0000
68/92 [=====================>........] - ETA: 1:36 - loss: 0.4225 - accuracy: 0.8264 - top_k_categorical_accuracy: 1.0000
69/92 [=====================>........] - ETA: 1:33 - loss: 0.4193 - accuracy: 0.8280 - top_k_categorical_accuracy: 1.0000
70/92 [=====================>........] - ETA: 1:29 - loss: 0.4165 - accuracy: 0.8296 - top_k_categorical_accuracy: 1.0000
71/92 [=====================>........] - ETA: 1:25 - loss: 0.4155 - accuracy: 0.8307 - top_k_categorical_accuracy: 1.0000
72/92 [======================>.......] - ETA: 1:22 - loss: 0.4131 - accuracy: 0.8322 - top_k_categorical_accuracy: 1.0000
73/92 [======================>.......] - ETA: 1:18 - loss: 0.4095 - accuracy: 0.8345 - top_k_categorical_accuracy: 1.0000
74/92 [======================>.......] - ETA: 1:15 - loss: 0.4066 - accuracy: 0.8363 - top_k_categorical_accuracy: 1.0000
75/92 [=======================>......] - ETA: 1:11 - loss: 0.4041 - accuracy: 0.8381 - top_k_categorical_accuracy: 1.0000
76/92 [=======================>......] - ETA: 1:07 - loss: 0.4025 - accuracy: 0.8394 - top_k_categorical_accuracy: 1.0000
77/92 [=======================>......] - ETA: 1:03 - loss: 0.3995 - accuracy: 0.8411 - top_k_categorical_accuracy: 1.0000
78/92 [========================>.....] - ETA: 59s - loss: 0.3966 - accuracy: 0.8431 - top_k_categorical_accuracy: 1.0000 
79/92 [========================>.....] - ETA: 55s - loss: 0.3941 - accuracy: 0.8447 - top_k_categorical_accuracy: 1.0000
80/92 [========================>.....] - ETA: 52s - loss: 0.3919 - accuracy: 0.8459 - top_k_categorical_accuracy: 1.0000
81/92 [=========================>....] - ETA: 47s - loss: 0.3887 - accuracy: 0.8478 - top_k_categorical_accuracy: 1.0000
82/92 [=========================>....] - ETA: 43s - loss: 0.3861 - accuracy: 0.8493 - top_k_categorical_accuracy: 1.0000
83/92 [=========================>....] - ETA: 39s - loss: 0.3832 - accuracy: 0.8507 - top_k_categorical_accuracy: 1.0000
84/92 [==========================>...] - ETA: 35s - loss: 0.3815 - accuracy: 0.8510 - top_k_categorical_accuracy: 1.0000
85/92 [==========================>...] - ETA: 31s - loss: 0.3819 - accuracy: 0.8494 - top_k_categorical_accuracy: 1.0000
86/92 [==========================>...] - ETA: 27s - loss: 0.3791 - accuracy: 0.8512 - top_k_categorical_accuracy: 1.0000
87/92 [===========================>..] - ETA: 23s - loss: 0.3776 - accuracy: 0.8526 - top_k_categorical_accuracy: 1.0000
88/92 [===========================>..] - ETA: 19s - loss: 0.3749 - accuracy: 0.8539 - top_k_categorical_accuracy: 1.0000
89/92 [===========================>..] - ETA: 15s - loss: 0.3726 - accuracy: 0.8552 - top_k_categorical_accuracy: 1.0000
90/92 [============================>.] - ETA: 10s - loss: 0.3713 - accuracy: 0.8554 - top_k_categorical_accuracy: 1.0000
91/92 [============================>.] - ETA: 6s - loss: 0.3698 - accuracy: 0.8560 - top_k_categorical_accuracy: 1.0000 
92/92 [============================>.] - ETA: 2s - loss: 0.3680 - accuracy: 0.8569 - top_k_categorical_accuracy: 1.0000
93/92 [==============================] - 497s 5s/step - loss: 0.3663 - accuracy: 0.8581 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.5793 - val_accuracy: 0.6532 - val_top_k_categorical_accuracy: 1.0000
Epoch 2/10

 1/92 [..............................] - ETA: 6:01 - loss: 0.1501 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 2/92 [..............................] - ETA: 5:50 - loss: 0.1773 - accuracy: 0.9688 - top_k_categorical_accuracy: 1.0000
 3/92 [..............................] - ETA: 5:43 - loss: 0.1792 - accuracy: 0.9479 - top_k_categorical_accuracy: 1.0000
 4/92 [>.............................] - ETA: 5:38 - loss: 0.2305 - accuracy: 0.8984 - top_k_categorical_accuracy: 1.0000
 5/92 [>.............................] - ETA: 5:33 - loss: 0.2280 - accuracy: 0.9062 - top_k_categorical_accuracy: 1.0000
 6/92 [>.............................] - ETA: 5:29 - loss: 0.2096 - accuracy: 0.9219 - top_k_categorical_accuracy: 1.0000
 7/92 [=>............................] - ETA: 5:25 - loss: 0.2047 - accuracy: 0.9241 - top_k_categorical_accuracy: 1.0000
 8/92 [=>............................] - ETA: 5:21 - loss: 0.2186 - accuracy: 0.9141 - top_k_categorical_accuracy: 1.0000
 9/92 [=>............................] - ETA: 5:17 - loss: 0.2214 - accuracy: 0.9132 - top_k_categorical_accuracy: 1.0000
10/92 [==>...........................] - ETA: 5:13 - loss: 0.2158 - accuracy: 0.9187 - top_k_categorical_accuracy: 1.0000
11/92 [==>...........................] - ETA: 5:09 - loss: 0.2197 - accuracy: 0.9176 - top_k_categorical_accuracy: 1.0000
12/92 [==>...........................] - ETA: 5:06 - loss: 0.2264 - accuracy: 0.9193 - top_k_categorical_accuracy: 1.0000
13/92 [===>..........................] - ETA: 5:02 - loss: 0.2289 - accuracy: 0.9159 - top_k_categorical_accuracy: 1.0000
14/92 [===>..........................] - ETA: 4:58 - loss: 0.2271 - accuracy: 0.9152 - top_k_categorical_accuracy: 1.0000
15/92 [===>..........................] - ETA: 4:54 - loss: 0.2227 - accuracy: 0.9187 - top_k_categorical_accuracy: 1.0000
16/92 [====>.........................] - ETA: 4:50 - loss: 0.2292 - accuracy: 0.9160 - top_k_categorical_accuracy: 1.0000
17/92 [====>.........................] - ETA: 4:52 - loss: 0.2236 - accuracy: 0.9210 - top_k_categorical_accuracy: 1.0000
18/92 [====>.........................] - ETA: 4:53 - loss: 0.2224 - accuracy: 0.9201 - top_k_categorical_accuracy: 1.0000
19/92 [=====>........................] - ETA: 4:54 - loss: 0.2173 - accuracy: 0.9227 - top_k_categorical_accuracy: 1.0000
20/92 [=====>........................] - ETA: 4:50 - loss: 0.2145 - accuracy: 0.9234 - top_k_categorical_accuracy: 1.0000
21/92 [=====>........................] - ETA: 4:51 - loss: 0.2137 - accuracy: 0.9211 - top_k_categorical_accuracy: 1.0000
22/92 [======>.......................] - ETA: 4:50 - loss: 0.2111 - accuracy: 0.9233 - top_k_categorical_accuracy: 1.0000
23/92 [======>.......................] - ETA: 4:49 - loss: 0.2084 - accuracy: 0.9239 - top_k_categorical_accuracy: 1.0000
24/92 [======>.......................] - ETA: 4:48 - loss: 0.2060 - accuracy: 0.9245 - top_k_categorical_accuracy: 1.0000
25/92 [=======>......................] - ETA: 4:47 - loss: 0.2049 - accuracy: 0.9250 - top_k_categorical_accuracy: 1.0000
26/92 [=======>......................] - ETA: 4:45 - loss: 0.2041 - accuracy: 0.9267 - top_k_categorical_accuracy: 1.0000
27/92 [=======>......................] - ETA: 4:43 - loss: 0.2026 - accuracy: 0.9259 - top_k_categorical_accuracy: 1.0000
28/92 [========>.....................] - ETA: 4:41 - loss: 0.2003 - accuracy: 0.9286 - top_k_categorical_accuracy: 1.0000
29/92 [========>.....................] - ETA: 4:38 - loss: 0.1991 - accuracy: 0.9289 - top_k_categorical_accuracy: 1.0000
30/92 [========>.....................] - ETA: 4:36 - loss: 0.1975 - accuracy: 0.9302 - top_k_categorical_accuracy: 1.0000
31/92 [=========>....................] - ETA: 4:33 - loss: 0.1973 - accuracy: 0.9294 - top_k_categorical_accuracy: 1.0000
32/92 [=========>....................] - ETA: 4:30 - loss: 0.1950 - accuracy: 0.9316 - top_k_categorical_accuracy: 1.0000
33/92 [=========>....................] - ETA: 4:27 - loss: 0.1929 - accuracy: 0.9337 - top_k_categorical_accuracy: 1.0000
34/92 [==========>...................] - ETA: 4:24 - loss: 0.1946 - accuracy: 0.9338 - top_k_categorical_accuracy: 1.0000
35/92 [==========>...................] - ETA: 4:19 - loss: 0.1940 - accuracy: 0.9348 - top_k_categorical_accuracy: 1.0000
36/92 [==========>...................] - ETA: 4:13 - loss: 0.1926 - accuracy: 0.9349 - top_k_categorical_accuracy: 1.0000
37/92 [==========>...................] - ETA: 4:08 - loss: 0.1907 - accuracy: 0.9367 - top_k_categorical_accuracy: 1.0000
38/92 [===========>..................] - ETA: 4:03 - loss: 0.1892 - accuracy: 0.9375 - top_k_categorical_accuracy: 1.0000
39/92 [===========>..................] - ETA: 3:57 - loss: 0.1892 - accuracy: 0.9375 - top_k_categorical_accuracy: 1.0000
40/92 [===========>..................] - ETA: 3:52 - loss: 0.1866 - accuracy: 0.9391 - top_k_categorical_accuracy: 1.0000
41/92 [============>.................] - ETA: 3:47 - loss: 0.1852 - accuracy: 0.9390 - top_k_categorical_accuracy: 1.0000
42/92 [============>.................] - ETA: 3:42 - loss: 0.1869 - accuracy: 0.9390 - top_k_categorical_accuracy: 1.0000
43/92 [============>.................] - ETA: 3:36 - loss: 0.1867 - accuracy: 0.9397 - top_k_categorical_accuracy: 1.0000
44/92 [=============>................] - ETA: 3:31 - loss: 0.1855 - accuracy: 0.9396 - top_k_categorical_accuracy: 1.0000
45/92 [=============>................] - ETA: 3:26 - loss: 0.1866 - accuracy: 0.9368 - top_k_categorical_accuracy: 1.0000
46/92 [=============>................] - ETA: 3:21 - loss: 0.1873 - accuracy: 0.9368 - top_k_categorical_accuracy: 1.0000
47/92 [==============>...............] - ETA: 3:16 - loss: 0.1850 - accuracy: 0.9382 - top_k_categorical_accuracy: 1.0000
48/92 [==============>...............] - ETA: 3:11 - loss: 0.1836 - accuracy: 0.9382 - top_k_categorical_accuracy: 1.0000
49/92 [==============>...............] - ETA: 3:07 - loss: 0.1826 - accuracy: 0.9388 - top_k_categorical_accuracy: 1.0000
50/92 [===============>..............] - ETA: 3:02 - loss: 0.1821 - accuracy: 0.9388 - top_k_categorical_accuracy: 1.0000
51/92 [===============>..............] - ETA: 2:57 - loss: 0.1821 - accuracy: 0.9393 - top_k_categorical_accuracy: 1.0000
52/92 [===============>..............] - ETA: 2:53 - loss: 0.1843 - accuracy: 0.9381 - top_k_categorical_accuracy: 1.0000
53/92 [================>.............] - ETA: 2:48 - loss: 0.1852 - accuracy: 0.9369 - top_k_categorical_accuracy: 1.0000
54/92 [================>.............] - ETA: 2:43 - loss: 0.1835 - accuracy: 0.9381 - top_k_categorical_accuracy: 1.0000
55/92 [================>.............] - ETA: 2:39 - loss: 0.1829 - accuracy: 0.9381 - top_k_categorical_accuracy: 1.0000
56/92 [=================>............] - ETA: 2:34 - loss: 0.1824 - accuracy: 0.9392 - top_k_categorical_accuracy: 1.0000
57/92 [=================>............] - ETA: 2:30 - loss: 0.1815 - accuracy: 0.9402 - top_k_categorical_accuracy: 1.0000
58/92 [=================>............] - ETA: 2:25 - loss: 0.1810 - accuracy: 0.9407 - top_k_categorical_accuracy: 1.0000
59/92 [==================>...........] - ETA: 2:21 - loss: 0.1801 - accuracy: 0.9417 - top_k_categorical_accuracy: 1.0000
60/92 [==================>...........] - ETA: 2:16 - loss: 0.1805 - accuracy: 0.9411 - top_k_categorical_accuracy: 1.0000
61/92 [==================>...........] - ETA: 2:12 - loss: 0.1788 - accuracy: 0.9421 - top_k_categorical_accuracy: 1.0000
62/92 [===================>..........] - ETA: 2:08 - loss: 0.1792 - accuracy: 0.9415 - top_k_categorical_accuracy: 1.0000
63/92 [===================>..........] - ETA: 2:03 - loss: 0.1776 - accuracy: 0.9425 - top_k_categorical_accuracy: 1.0000
64/92 [===================>..........] - ETA: 1:59 - loss: 0.1775 - accuracy: 0.9424 - top_k_categorical_accuracy: 1.0000
65/92 [====================>.........] - ETA: 1:55 - loss: 0.1773 - accuracy: 0.9428 - top_k_categorical_accuracy: 1.0000
66/92 [====================>.........] - ETA: 1:50 - loss: 0.1759 - accuracy: 0.9437 - top_k_categorical_accuracy: 1.0000
67/92 [====================>.........] - ETA: 1:46 - loss: 0.1756 - accuracy: 0.9436 - top_k_categorical_accuracy: 1.0000
68/92 [=====================>........] - ETA: 1:42 - loss: 0.1745 - accuracy: 0.9444 - top_k_categorical_accuracy: 1.0000
69/92 [=====================>........] - ETA: 1:37 - loss: 0.1737 - accuracy: 0.9443 - top_k_categorical_accuracy: 1.0000
70/92 [=====================>........] - ETA: 1:33 - loss: 0.1729 - accuracy: 0.9446 - top_k_categorical_accuracy: 1.0000
71/92 [=====================>........] - ETA: 1:29 - loss: 0.1714 - accuracy: 0.9454 - top_k_categorical_accuracy: 1.0000
72/92 [======================>.......] - ETA: 1:25 - loss: 0.1701 - accuracy: 0.9462 - top_k_categorical_accuracy: 1.0000
73/92 [======================>.......] - ETA: 1:20 - loss: 0.1691 - accuracy: 0.9469 - top_k_categorical_accuracy: 1.0000
74/92 [======================>.......] - ETA: 1:16 - loss: 0.1702 - accuracy: 0.9464 - top_k_categorical_accuracy: 1.0000
75/92 [=======================>......] - ETA: 1:12 - loss: 0.1726 - accuracy: 0.9442 - top_k_categorical_accuracy: 1.0000
76/92 [=======================>......] - ETA: 1:08 - loss: 0.1718 - accuracy: 0.9445 - top_k_categorical_accuracy: 1.0000
77/92 [=======================>......] - ETA: 1:04 - loss: 0.1707 - accuracy: 0.9448 - top_k_categorical_accuracy: 1.0000
78/92 [========================>.....] - ETA: 1:00 - loss: 0.1705 - accuracy: 0.9451 - top_k_categorical_accuracy: 1.0000
79/92 [========================>.....] - ETA: 55s - loss: 0.1697 - accuracy: 0.9454 - top_k_categorical_accuracy: 1.0000 
80/92 [========================>.....] - ETA: 51s - loss: 0.1718 - accuracy: 0.9445 - top_k_categorical_accuracy: 1.0000
81/92 [=========================>....] - ETA: 47s - loss: 0.1728 - accuracy: 0.9433 - top_k_categorical_accuracy: 1.0000
82/92 [=========================>....] - ETA: 43s - loss: 0.1724 - accuracy: 0.9436 - top_k_categorical_accuracy: 1.0000
83/92 [=========================>....] - ETA: 39s - loss: 0.1719 - accuracy: 0.9435 - top_k_categorical_accuracy: 1.0000
84/92 [==========================>...] - ETA: 35s - loss: 0.1721 - accuracy: 0.9435 - top_k_categorical_accuracy: 1.0000
85/92 [==========================>...] - ETA: 31s - loss: 0.1714 - accuracy: 0.9438 - top_k_categorical_accuracy: 1.0000
86/92 [==========================>...] - ETA: 27s - loss: 0.1705 - accuracy: 0.9440 - top_k_categorical_accuracy: 1.0000
87/92 [===========================>..] - ETA: 23s - loss: 0.1698 - accuracy: 0.9443 - top_k_categorical_accuracy: 1.0000
88/92 [===========================>..] - ETA: 18s - loss: 0.1690 - accuracy: 0.9450 - top_k_categorical_accuracy: 1.0000
89/92 [===========================>..] - ETA: 14s - loss: 0.1679 - accuracy: 0.9454 - top_k_categorical_accuracy: 1.0000
90/92 [============================>.] - ETA: 10s - loss: 0.1670 - accuracy: 0.9456 - top_k_categorical_accuracy: 1.0000
91/92 [============================>.] - ETA: 6s - loss: 0.1668 - accuracy: 0.9456 - top_k_categorical_accuracy: 1.0000 
92/92 [============================>.] - ETA: 2s - loss: 0.1659 - accuracy: 0.9461 - top_k_categorical_accuracy: 1.0000
93/92 [==============================] - 519s 6s/step - loss: 0.1646 - accuracy: 0.9467 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.6451 - val_top_k_categorical_accuracy: 1.0000
Epoch 3/10

 1/92 [..............................] - ETA: 5:54 - loss: 0.0654 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 2/92 [..............................] - ETA: 5:46 - loss: 0.0754 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000
 3/92 [..............................] - ETA: 5:40 - loss: 0.0710 - accuracy: 0.9896 - top_k_categorical_accuracy: 1.0000
 4/92 [>.............................] - ETA: 5:35 - loss: 0.1165 - accuracy: 0.9688 - top_k_categorical_accuracy: 1.0000
 5/92 [>.............................] - ETA: 5:31 - loss: 0.1156 - accuracy: 0.9688 - top_k_categorical_accuracy: 1.0000
 6/92 [>.............................] - ETA: 5:26 - loss: 0.1168 - accuracy: 0.9740 - top_k_categorical_accuracy: 1.0000
 7/92 [=>............................] - ETA: 5:23 - loss: 0.1102 - accuracy: 0.9777 - top_k_categorical_accuracy: 1.0000
 8/92 [=>............................] - ETA: 5:18 - loss: 0.1104 - accuracy: 0.9805 - top_k_categorical_accuracy: 1.0000
 9/92 [=>............................] - ETA: 5:15 - loss: 0.1123 - accuracy: 0.9792 - top_k_categorical_accuracy: 1.0000
10/92 [==>...........................] - ETA: 5:11 - loss: 0.1100 - accuracy: 0.9781 - top_k_categorical_accuracy: 1.0000
11/92 [==>...........................] - ETA: 5:07 - loss: 0.1088 - accuracy: 0.9773 - top_k_categorical_accuracy: 1.0000
12/92 [==>...........................] - ETA: 5:03 - loss: 0.1047 - accuracy: 0.9792 - top_k_categorical_accuracy: 1.0000
13/92 [===>..........................] - ETA: 4:59 - loss: 0.1091 - accuracy: 0.9736 - top_k_categorical_accuracy: 1.0000
14/92 [===>..........................] - ETA: 4:56 - loss: 0.1258 - accuracy: 0.9665 - top_k_categorical_accuracy: 1.0000
15/92 [===>..........................] - ETA: 4:52 - loss: 0.1258 - accuracy: 0.9667 - top_k_categorical_accuracy: 1.0000
16/92 [====>.........................] - ETA: 4:48 - loss: 0.1223 - accuracy: 0.9688 - top_k_categorical_accuracy: 1.0000
17/92 [====>.........................] - ETA: 4:44 - loss: 0.1192 - accuracy: 0.9688 - top_k_categorical_accuracy: 1.0000
18/92 [====>.........................] - ETA: 4:41 - loss: 0.1151 - accuracy: 0.9705 - top_k_categorical_accuracy: 1.0000
19/92 [=====>........................] - ETA: 4:37 - loss: 0.1168 - accuracy: 0.9688 - top_k_categorical_accuracy: 1.0000
20/92 [=====>........................] - ETA: 4:33 - loss: 0.1150 - accuracy: 0.9703 - top_k_categorical_accuracy: 1.0000
21/92 [=====>........................] - ETA: 4:30 - loss: 0.1129 - accuracy: 0.9717 - top_k_categorical_accuracy: 1.0000
22/92 [======>.......................] - ETA: 4:26 - loss: 0.1161 - accuracy: 0.9730 - top_k_categorical_accuracy: 1.0000
23/92 [======>.......................] - ETA: 4:22 - loss: 0.1141 - accuracy: 0.9742 - top_k_categorical_accuracy: 1.0000
24/92 [======>.......................] - ETA: 4:18 - loss: 0.1111 - accuracy: 0.9753 - top_k_categorical_accuracy: 1.0000
25/92 [=======>......................] - ETA: 4:14 - loss: 0.1130 - accuracy: 0.9750 - top_k_categorical_accuracy: 1.0000
26/92 [=======>......................] - ETA: 4:11 - loss: 0.1108 - accuracy: 0.9760 - top_k_categorical_accuracy: 1.0000
27/92 [=======>......................] - ETA: 4:07 - loss: 0.1100 - accuracy: 0.9769 - top_k_categorical_accuracy: 1.0000
28/92 [========>.....................] - ETA: 4:03 - loss: 0.1153 - accuracy: 0.9732 - top_k_categorical_accuracy: 1.0000
29/92 [========>.....................] - ETA: 3:59 - loss: 0.1180 - accuracy: 0.9698 - top_k_categorical_accuracy: 1.0000
30/92 [========>.....................] - ETA: 3:55 - loss: 0.1159 - accuracy: 0.9708 - top_k_categorical_accuracy: 1.0000
31/92 [=========>....................] - ETA: 3:52 - loss: 0.1178 - accuracy: 0.9698 - top_k_categorical_accuracy: 1.0000
32/92 [=========>....................] - ETA: 3:48 - loss: 0.1175 - accuracy: 0.9707 - top_k_categorical_accuracy: 1.0000
33/92 [=========>....................] - ETA: 3:44 - loss: 0.1197 - accuracy: 0.9697 - top_k_categorical_accuracy: 1.0000
34/92 [==========>...................] - ETA: 3:40 - loss: 0.1198 - accuracy: 0.9688 - top_k_categorical_accuracy: 1.0000
35/92 [==========>...................] - ETA: 3:37 - loss: 0.1184 - accuracy: 0.9696 - top_k_categorical_accuracy: 1.0000
36/92 [==========>...................] - ETA: 3:31 - loss: 0.1205 - accuracy: 0.9685 - top_k_categorical_accuracy: 1.0000
37/92 [==========>...................] - ETA: 3:27 - loss: 0.1283 - accuracy: 0.9634 - top_k_categorical_accuracy: 1.0000
38/92 [===========>..................] - ETA: 3:24 - loss: 0.1314 - accuracy: 0.9610 - top_k_categorical_accuracy: 1.0000
39/92 [===========>..................] - ETA: 3:20 - loss: 0.1297 - accuracy: 0.9620 - top_k_categorical_accuracy: 1.0000
40/92 [===========>..................] - ETA: 3:16 - loss: 0.1279 - accuracy: 0.9630 - top_k_categorical_accuracy: 1.0000
41/92 [============>.................] - ETA: 3:12 - loss: 0.1265 - accuracy: 0.9639 - top_k_categorical_accuracy: 1.0000
42/92 [============>.................] - ETA: 3:08 - loss: 0.1257 - accuracy: 0.9640 - top_k_categorical_accuracy: 1.0000
43/92 [============>.................] - ETA: 3:05 - loss: 0.1249 - accuracy: 0.9649 - top_k_categorical_accuracy: 1.0000
44/92 [=============>................] - ETA: 3:01 - loss: 0.1240 - accuracy: 0.9657 - top_k_categorical_accuracy: 1.0000
45/92 [=============>................] - ETA: 2:57 - loss: 0.1234 - accuracy: 0.9657 - top_k_categorical_accuracy: 1.0000
46/92 [=============>................] - ETA: 2:53 - loss: 0.1237 - accuracy: 0.9651 - top_k_categorical_accuracy: 1.0000
47/92 [==============>...............] - ETA: 2:49 - loss: 0.1237 - accuracy: 0.9645 - top_k_categorical_accuracy: 1.0000
48/92 [==============>...............] - ETA: 2:46 - loss: 0.1232 - accuracy: 0.9646 - top_k_categorical_accuracy: 1.0000
49/92 [==============>...............] - ETA: 2:42 - loss: 0.1218 - accuracy: 0.9653 - top_k_categorical_accuracy: 1.0000
50/92 [===============>..............] - ETA: 2:38 - loss: 0.1201 - accuracy: 0.9660 - top_k_categorical_accuracy: 1.0000
51/92 [===============>..............] - ETA: 2:35 - loss: 0.1201 - accuracy: 0.9661 - top_k_categorical_accuracy: 1.0000
52/92 [===============>..............] - ETA: 2:31 - loss: 0.1204 - accuracy: 0.9655 - top_k_categorical_accuracy: 1.0000
53/92 [================>.............] - ETA: 2:27 - loss: 0.1209 - accuracy: 0.9650 - top_k_categorical_accuracy: 1.0000
54/92 [================>.............] - ETA: 2:24 - loss: 0.1197 - accuracy: 0.9657 - top_k_categorical_accuracy: 1.0000
55/92 [================>.............] - ETA: 2:20 - loss: 0.1186 - accuracy: 0.9663 - top_k_categorical_accuracy: 1.0000
56/92 [=================>............] - ETA: 2:16 - loss: 0.1173 - accuracy: 0.9669 - top_k_categorical_accuracy: 1.0000
57/92 [=================>............] - ETA: 2:12 - loss: 0.1164 - accuracy: 0.9675 - top_k_categorical_accuracy: 1.0000
58/92 [=================>............] - ETA: 2:09 - loss: 0.1152 - accuracy: 0.9680 - top_k_categorical_accuracy: 1.0000
59/92 [==================>...........] - ETA: 2:05 - loss: 0.1147 - accuracy: 0.9681 - top_k_categorical_accuracy: 1.0000
60/92 [==================>...........] - ETA: 2:02 - loss: 0.1149 - accuracy: 0.9681 - top_k_categorical_accuracy: 1.0000
61/92 [==================>...........] - ETA: 1:59 - loss: 0.1145 - accuracy: 0.9686 - top_k_categorical_accuracy: 1.0000
62/92 [===================>..........] - ETA: 1:56 - loss: 0.1140 - accuracy: 0.9686 - top_k_categorical_accuracy: 1.0000
63/92 [===================>..........] - ETA: 1:52 - loss: 0.1132 - accuracy: 0.9691 - top_k_categorical_accuracy: 1.0000
64/92 [===================>..........] - ETA: 1:49 - loss: 0.1150 - accuracy: 0.9691 - top_k_categorical_accuracy: 1.0000
65/92 [====================>.........] - ETA: 1:46 - loss: 0.1140 - accuracy: 0.9696 - top_k_categorical_accuracy: 1.0000
66/92 [====================>.........] - ETA: 1:43 - loss: 0.1134 - accuracy: 0.9696 - top_k_categorical_accuracy: 1.0000
67/92 [====================>.........] - ETA: 1:39 - loss: 0.1147 - accuracy: 0.9691 - top_k_categorical_accuracy: 1.0000
68/92 [=====================>........] - ETA: 1:36 - loss: 0.1140 - accuracy: 0.9695 - top_k_categorical_accuracy: 1.0000
69/92 [=====================>........] - ETA: 1:33 - loss: 0.1136 - accuracy: 0.9695 - top_k_categorical_accuracy: 1.0000
70/92 [=====================>........] - ETA: 1:29 - loss: 0.1127 - accuracy: 0.9700 - top_k_categorical_accuracy: 1.0000
71/92 [=====================>........] - ETA: 1:25 - loss: 0.1125 - accuracy: 0.9704 - top_k_categorical_accuracy: 1.0000
72/92 [======================>.......] - ETA: 1:22 - loss: 0.1117 - accuracy: 0.9708 - top_k_categorical_accuracy: 1.0000
73/92 [======================>.......] - ETA: 1:18 - loss: 0.1112 - accuracy: 0.9712 - top_k_categorical_accuracy: 1.0000
74/92 [======================>.......] - ETA: 1:15 - loss: 0.1107 - accuracy: 0.9712 - top_k_categorical_accuracy: 1.0000
75/92 [=======================>......] - ETA: 1:11 - loss: 0.1106 - accuracy: 0.9715 - top_k_categorical_accuracy: 1.0000
76/92 [=======================>......] - ETA: 1:07 - loss: 0.1101 - accuracy: 0.9719 - top_k_categorical_accuracy: 1.0000
77/92 [=======================>......] - ETA: 1:03 - loss: 0.1102 - accuracy: 0.9719 - top_k_categorical_accuracy: 1.0000
78/92 [========================>.....] - ETA: 59s - loss: 0.1106 - accuracy: 0.9714 - top_k_categorical_accuracy: 1.0000 
79/92 [========================>.....] - ETA: 55s - loss: 0.1112 - accuracy: 0.9714 - top_k_categorical_accuracy: 1.0000
80/92 [========================>.....] - ETA: 51s - loss: 0.1111 - accuracy: 0.9714 - top_k_categorical_accuracy: 1.0000
81/92 [=========================>....] - ETA: 47s - loss: 0.1104 - accuracy: 0.9717 - top_k_categorical_accuracy: 1.0000
82/92 [=========================>....] - ETA: 43s - loss: 0.1098 - accuracy: 0.9721 - top_k_categorical_accuracy: 1.0000
83/92 [=========================>....] - ETA: 39s - loss: 0.1094 - accuracy: 0.9724 - top_k_categorical_accuracy: 1.0000
84/92 [==========================>...] - ETA: 35s - loss: 0.1087 - accuracy: 0.9727 - top_k_categorical_accuracy: 1.0000
85/92 [==========================>...] - ETA: 31s - loss: 0.1079 - accuracy: 0.9731 - top_k_categorical_accuracy: 1.0000
86/92 [==========================>...] - ETA: 26s - loss: 0.1074 - accuracy: 0.9734 - top_k_categorical_accuracy: 1.0000
87/92 [===========================>..] - ETA: 22s - loss: 0.1069 - accuracy: 0.9733 - top_k_categorical_accuracy: 1.0000
88/92 [===========================>..] - ETA: 18s - loss: 0.1067 - accuracy: 0.9733 - top_k_categorical_accuracy: 1.0000
89/92 [===========================>..] - ETA: 14s - loss: 0.1064 - accuracy: 0.9736 - top_k_categorical_accuracy: 1.0000
90/92 [============================>.] - ETA: 10s - loss: 0.1109 - accuracy: 0.9711 - top_k_categorical_accuracy: 1.0000
91/92 [============================>.] - ETA: 6s - loss: 0.1105 - accuracy: 0.9711 - top_k_categorical_accuracy: 1.0000 
92/92 [============================>.] - ETA: 2s - loss: 0.1099 - accuracy: 0.9714 - top_k_categorical_accuracy: 1.0000
93/92 [==============================] - 492s 5s/step - loss: 0.1098 - accuracy: 0.9713 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.6471 - val_top_k_categorical_accuracy: 1.0000
Epoch 4/10

 1/92 [..............................] - ETA: 5:59 - loss: 0.1449 - accuracy: 0.9688 - top_k_categorical_accuracy: 1.0000
 2/92 [..............................] - ETA: 5:48 - loss: 0.0994 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000
 3/92 [..............................] - ETA: 5:42 - loss: 0.1492 - accuracy: 0.9583 - top_k_categorical_accuracy: 1.0000
 4/92 [>.............................] - ETA: 5:37 - loss: 0.1507 - accuracy: 0.9531 - top_k_categorical_accuracy: 1.0000
 5/92 [>.............................] - ETA: 5:33 - loss: 0.1310 - accuracy: 0.9625 - top_k_categorical_accuracy: 1.0000
 6/92 [>.............................] - ETA: 5:28 - loss: 0.1149 - accuracy: 0.9688 - top_k_categorical_accuracy: 1.0000
 7/92 [=>............................] - ETA: 5:23 - loss: 0.1095 - accuracy: 0.9732 - top_k_categorical_accuracy: 1.0000
 8/92 [=>............................] - ETA: 5:18 - loss: 0.1108 - accuracy: 0.9688 - top_k_categorical_accuracy: 1.0000
 9/92 [=>............................] - ETA: 5:13 - loss: 0.1070 - accuracy: 0.9722 - top_k_categorical_accuracy: 1.0000
10/92 [==>...........................] - ETA: 5:09 - loss: 0.1063 - accuracy: 0.9719 - top_k_categorical_accuracy: 1.0000
11/92 [==>...........................] - ETA: 5:05 - loss: 0.1005 - accuracy: 0.9744 - top_k_categorical_accuracy: 1.0000
12/92 [==>...........................] - ETA: 5:01 - loss: 0.0956 - accuracy: 0.9766 - top_k_categorical_accuracy: 1.0000
13/92 [===>..........................] - ETA: 4:58 - loss: 0.0915 - accuracy: 0.9784 - top_k_categorical_accuracy: 1.0000
14/92 [===>..........................] - ETA: 4:54 - loss: 0.0892 - accuracy: 0.9799 - top_k_categorical_accuracy: 1.0000
15/92 [===>..........................] - ETA: 4:51 - loss: 0.0880 - accuracy: 0.9812 - top_k_categorical_accuracy: 1.0000
16/92 [====>.........................] - ETA: 4:47 - loss: 0.0886 - accuracy: 0.9805 - top_k_categorical_accuracy: 1.0000
17/92 [====>.........................] - ETA: 4:44 - loss: 0.0880 - accuracy: 0.9798 - top_k_categorical_accuracy: 1.0000
18/92 [====>.........................] - ETA: 4:40 - loss: 0.0871 - accuracy: 0.9809 - top_k_categorical_accuracy: 1.0000
19/92 [=====>........................] - ETA: 4:37 - loss: 0.0851 - accuracy: 0.9819 - top_k_categorical_accuracy: 1.0000
20/92 [=====>........................] - ETA: 4:33 - loss: 0.0842 - accuracy: 0.9812 - top_k_categorical_accuracy: 1.0000
21/92 [=====>........................] - ETA: 4:29 - loss: 0.0821 - accuracy: 0.9821 - top_k_categorical_accuracy: 1.0000
22/92 [======>.......................] - ETA: 4:26 - loss: 0.0805 - accuracy: 0.9815 - top_k_categorical_accuracy: 1.0000
23/92 [======>.......................] - ETA: 4:26 - loss: 0.0802 - accuracy: 0.9823 - top_k_categorical_accuracy: 1.0000
24/92 [======>.......................] - ETA: 4:26 - loss: 0.0796 - accuracy: 0.9831 - top_k_categorical_accuracy: 1.0000
25/92 [=======>......................] - ETA: 4:25 - loss: 0.0788 - accuracy: 0.9825 - top_k_categorical_accuracy: 1.0000
26/92 [=======>......................] - ETA: 4:22 - loss: 0.0804 - accuracy: 0.9808 - top_k_categorical_accuracy: 1.0000
27/92 [=======>......................] - ETA: 4:21 - loss: 0.0807 - accuracy: 0.9815 - top_k_categorical_accuracy: 1.0000
28/92 [========>.....................] - ETA: 4:20 - loss: 0.0787 - accuracy: 0.9821 - top_k_categorical_accuracy: 1.0000
29/92 [========>.....................] - ETA: 4:18 - loss: 0.0774 - accuracy: 0.9828 - top_k_categorical_accuracy: 1.0000
30/92 [========>.....................] - ETA: 4:17 - loss: 0.0770 - accuracy: 0.9833 - top_k_categorical_accuracy: 1.0000
31/92 [=========>....................] - ETA: 4:15 - loss: 0.0777 - accuracy: 0.9829 - top_k_categorical_accuracy: 1.0000
32/92 [=========>....................] - ETA: 4:13 - loss: 0.0782 - accuracy: 0.9834 - top_k_categorical_accuracy: 1.0000
33/92 [=========>....................] - ETA: 4:11 - loss: 0.0787 - accuracy: 0.9839 - top_k_categorical_accuracy: 1.0000
34/92 [==========>...................] - ETA: 4:08 - loss: 0.0788 - accuracy: 0.9835 - top_k_categorical_accuracy: 1.0000
35/92 [==========>...................] - ETA: 4:06 - loss: 0.0793 - accuracy: 0.9821 - top_k_categorical_accuracy: 1.0000
36/92 [==========>...................] - ETA: 4:03 - loss: 0.0779 - accuracy: 0.9826 - top_k_categorical_accuracy: 1.0000
37/92 [==========>...................] - ETA: 4:00 - loss: 0.0776 - accuracy: 0.9831 - top_k_categorical_accuracy: 1.0000
38/92 [===========>..................] - ETA: 3:57 - loss: 0.0774 - accuracy: 0.9836 - top_k_categorical_accuracy: 1.0000
39/92 [===========>..................] - ETA: 3:54 - loss: 0.0813 - accuracy: 0.9832 - top_k_categorical_accuracy: 1.0000
40/92 [===========>..................] - ETA: 3:51 - loss: 0.0826 - accuracy: 0.9828 - top_k_categorical_accuracy: 1.0000
41/92 [============>.................] - ETA: 3:46 - loss: 0.0819 - accuracy: 0.9832 - top_k_categorical_accuracy: 1.0000
42/92 [============>.................] - ETA: 3:41 - loss: 0.0817 - accuracy: 0.9829 - top_k_categorical_accuracy: 1.0000
43/92 [============>.................] - ETA: 3:36 - loss: 0.0807 - accuracy: 0.9833 - top_k_categorical_accuracy: 1.0000
44/92 [=============>................] - ETA: 3:31 - loss: 0.0799 - accuracy: 0.9837 - top_k_categorical_accuracy: 1.0000
45/92 [=============>................] - ETA: 3:26 - loss: 0.0812 - accuracy: 0.9826 - top_k_categorical_accuracy: 1.0000
46/92 [=============>................] - ETA: 3:21 - loss: 0.0805 - accuracy: 0.9830 - top_k_categorical_accuracy: 1.0000
47/92 [==============>...............] - ETA: 3:16 - loss: 0.0799 - accuracy: 0.9834 - top_k_categorical_accuracy: 1.0000
48/92 [==============>...............] - ETA: 3:12 - loss: 0.0802 - accuracy: 0.9831 - top_k_categorical_accuracy: 1.0000
49/92 [==============>...............] - ETA: 3:07 - loss: 0.0794 - accuracy: 0.9834 - top_k_categorical_accuracy: 1.0000
50/92 [===============>..............] - ETA: 3:03 - loss: 0.0791 - accuracy: 0.9837 - top_k_categorical_accuracy: 1.0000
51/92 [===============>..............] - ETA: 2:58 - loss: 0.0785 - accuracy: 0.9841 - top_k_categorical_accuracy: 1.0000
52/92 [===============>..............] - ETA: 2:53 - loss: 0.0777 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000
53/92 [================>.............] - ETA: 2:49 - loss: 0.0771 - accuracy: 0.9847 - top_k_categorical_accuracy: 1.0000
54/92 [================>.............] - ETA: 2:44 - loss: 0.0777 - accuracy: 0.9850 - top_k_categorical_accuracy: 1.0000
55/92 [================>.............] - ETA: 2:40 - loss: 0.0778 - accuracy: 0.9847 - top_k_categorical_accuracy: 1.0000
56/92 [=================>............] - ETA: 2:35 - loss: 0.0783 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000
57/92 [=================>............] - ETA: 2:31 - loss: 0.0787 - accuracy: 0.9836 - top_k_categorical_accuracy: 1.0000
58/92 [=================>............] - ETA: 2:26 - loss: 0.0789 - accuracy: 0.9833 - top_k_categorical_accuracy: 1.0000
59/92 [==================>...........] - ETA: 2:22 - loss: 0.0787 - accuracy: 0.9831 - top_k_categorical_accuracy: 1.0000
60/92 [==================>...........] - ETA: 2:18 - loss: 0.0783 - accuracy: 0.9833 - top_k_categorical_accuracy: 1.0000
61/92 [==================>...........] - ETA: 2:13 - loss: 0.0800 - accuracy: 0.9826 - top_k_categorical_accuracy: 1.0000
62/92 [===================>..........] - ETA: 2:09 - loss: 0.0792 - accuracy: 0.9829 - top_k_categorical_accuracy: 1.0000
63/92 [===================>..........] - ETA: 2:05 - loss: 0.0805 - accuracy: 0.9826 - top_k_categorical_accuracy: 1.0000
64/92 [===================>..........] - ETA: 2:00 - loss: 0.0816 - accuracy: 0.9824 - top_k_categorical_accuracy: 1.0000
65/92 [====================>.........] - ETA: 1:56 - loss: 0.0824 - accuracy: 0.9822 - top_k_categorical_accuracy: 1.0000
66/92 [====================>.........] - ETA: 1:52 - loss: 0.0816 - accuracy: 0.9825 - top_k_categorical_accuracy: 1.0000
67/92 [====================>.........] - ETA: 1:47 - loss: 0.0808 - accuracy: 0.9827 - top_k_categorical_accuracy: 1.0000
68/92 [=====================>........] - ETA: 1:43 - loss: 0.0806 - accuracy: 0.9830 - top_k_categorical_accuracy: 1.0000
69/92 [=====================>........] - ETA: 1:39 - loss: 0.0797 - accuracy: 0.9832 - top_k_categorical_accuracy: 1.0000
70/92 [=====================>........] - ETA: 1:34 - loss: 0.0796 - accuracy: 0.9835 - top_k_categorical_accuracy: 1.0000
71/92 [=====================>........] - ETA: 1:30 - loss: 0.0804 - accuracy: 0.9828 - top_k_categorical_accuracy: 1.0000
72/92 [======================>.......] - ETA: 1:26 - loss: 0.0796 - accuracy: 0.9831 - top_k_categorical_accuracy: 1.0000
73/92 [======================>.......] - ETA: 1:22 - loss: 0.0793 - accuracy: 0.9833 - top_k_categorical_accuracy: 1.0000
74/92 [======================>.......] - ETA: 1:17 - loss: 0.0805 - accuracy: 0.9823 - top_k_categorical_accuracy: 1.0000
75/92 [=======================>......] - ETA: 1:13 - loss: 0.0807 - accuracy: 0.9825 - top_k_categorical_accuracy: 1.0000
76/92 [=======================>......] - ETA: 1:09 - loss: 0.0807 - accuracy: 0.9827 - top_k_categorical_accuracy: 1.0000
77/92 [=======================>......] - ETA: 1:05 - loss: 0.0806 - accuracy: 0.9825 - top_k_categorical_accuracy: 1.0000
78/92 [========================>.....] - ETA: 1:01 - loss: 0.0801 - accuracy: 0.9828 - top_k_categorical_accuracy: 1.0000
79/92 [========================>.....] - ETA: 56s - loss: 0.0800 - accuracy: 0.9826 - top_k_categorical_accuracy: 1.0000 
80/92 [========================>.....] - ETA: 52s - loss: 0.0794 - accuracy: 0.9828 - top_k_categorical_accuracy: 1.0000
81/92 [=========================>....] - ETA: 48s - loss: 0.0796 - accuracy: 0.9823 - top_k_categorical_accuracy: 1.0000
82/92 [=========================>....] - ETA: 44s - loss: 0.0795 - accuracy: 0.9825 - top_k_categorical_accuracy: 1.0000
83/92 [=========================>....] - ETA: 40s - loss: 0.0788 - accuracy: 0.9827 - top_k_categorical_accuracy: 1.0000
84/92 [==========================>...] - ETA: 35s - loss: 0.0787 - accuracy: 0.9829 - top_k_categorical_accuracy: 1.0000
85/92 [==========================>...] - ETA: 31s - loss: 0.0784 - accuracy: 0.9831 - top_k_categorical_accuracy: 1.0000
86/92 [==========================>...] - ETA: 27s - loss: 0.0785 - accuracy: 0.9829 - top_k_categorical_accuracy: 1.0000
87/92 [===========================>..] - ETA: 23s - loss: 0.0813 - accuracy: 0.9813 - top_k_categorical_accuracy: 1.0000
88/92 [===========================>..] - ETA: 19s - loss: 0.0826 - accuracy: 0.9808 - top_k_categorical_accuracy: 1.0000
89/92 [===========================>..] - ETA: 15s - loss: 0.0828 - accuracy: 0.9806 - top_k_categorical_accuracy: 1.0000
90/92 [============================>.] - ETA: 11s - loss: 0.0822 - accuracy: 0.9808 - top_k_categorical_accuracy: 1.0000
91/92 [============================>.] - ETA: 6s - loss: 0.0825 - accuracy: 0.9810 - top_k_categorical_accuracy: 1.0000 
92/92 [============================>.] - ETA: 2s - loss: 0.0821 - accuracy: 0.9813 - top_k_categorical_accuracy: 1.0000
93/92 [==============================] - 507s 5s/step - loss: 0.0823 - accuracy: 0.9811 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.5865 - val_top_k_categorical_accuracy: 1.0000
Epoch 5/10

 1/92 [..............................] - ETA: 6:17 - loss: 0.0635 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 2/92 [..............................] - ETA: 6:07 - loss: 0.0546 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 3/92 [..............................] - ETA: 6:01 - loss: 0.0944 - accuracy: 0.9792 - top_k_categorical_accuracy: 1.0000
 4/92 [>.............................] - ETA: 5:56 - loss: 0.1456 - accuracy: 0.9453 - top_k_categorical_accuracy: 1.0000
 5/92 [>.............................] - ETA: 5:51 - loss: 0.1218 - accuracy: 0.9563 - top_k_categorical_accuracy: 1.0000
 6/92 [>.............................] - ETA: 5:47 - loss: 0.1148 - accuracy: 0.9583 - top_k_categorical_accuracy: 1.0000
 7/92 [=>............................] - ETA: 5:42 - loss: 0.1030 - accuracy: 0.9643 - top_k_categorical_accuracy: 1.0000
 8/92 [=>............................] - ETA: 5:38 - loss: 0.1035 - accuracy: 0.9609 - top_k_categorical_accuracy: 1.0000
 9/92 [=>............................] - ETA: 5:34 - loss: 0.0985 - accuracy: 0.9618 - top_k_categorical_accuracy: 1.0000
10/92 [==>...........................] - ETA: 5:29 - loss: 0.0962 - accuracy: 0.9656 - top_k_categorical_accuracy: 1.0000
11/92 [==>...........................] - ETA: 5:25 - loss: 0.0965 - accuracy: 0.9659 - top_k_categorical_accuracy: 1.0000
12/92 [==>...........................] - ETA: 5:21 - loss: 0.0938 - accuracy: 0.9688 - top_k_categorical_accuracy: 1.0000
13/92 [===>..........................] - ETA: 5:17 - loss: 0.0935 - accuracy: 0.9712 - top_k_categorical_accuracy: 1.0000
14/92 [===>..........................] - ETA: 5:13 - loss: 0.0887 - accuracy: 0.9732 - top_k_categorical_accuracy: 1.0000
15/92 [===>..........................] - ETA: 5:08 - loss: 0.0910 - accuracy: 0.9708 - top_k_categorical_accuracy: 1.0000
16/92 [====>.........................] - ETA: 5:04 - loss: 0.0895 - accuracy: 0.9707 - top_k_categorical_accuracy: 1.0000
17/92 [====>.........................] - ETA: 4:58 - loss: 0.0873 - accuracy: 0.9724 - top_k_categorical_accuracy: 1.0000
18/92 [====>.........................] - ETA: 4:53 - loss: 0.0845 - accuracy: 0.9740 - top_k_categorical_accuracy: 1.0000
19/92 [=====>........................] - ETA: 4:48 - loss: 0.0820 - accuracy: 0.9753 - top_k_categorical_accuracy: 1.0000
20/92 [=====>........................] - ETA: 4:44 - loss: 0.0798 - accuracy: 0.9766 - top_k_categorical_accuracy: 1.0000
21/92 [=====>........................] - ETA: 4:40 - loss: 0.0774 - accuracy: 0.9777 - top_k_categorical_accuracy: 1.0000
22/92 [======>.......................] - ETA: 4:36 - loss: 0.0760 - accuracy: 0.9787 - top_k_categorical_accuracy: 1.0000
23/92 [======>.......................] - ETA: 4:31 - loss: 0.0757 - accuracy: 0.9796 - top_k_categorical_accuracy: 1.0000
24/92 [======>.......................] - ETA: 4:27 - loss: 0.0763 - accuracy: 0.9805 - top_k_categorical_accuracy: 1.0000
25/92 [=======>......................] - ETA: 4:23 - loss: 0.0768 - accuracy: 0.9800 - top_k_categorical_accuracy: 1.0000
26/92 [=======>......................] - ETA: 4:16 - loss: 0.0755 - accuracy: 0.9805 - top_k_categorical_accuracy: 1.0000
27/92 [=======>......................] - ETA: 4:12 - loss: 0.0750 - accuracy: 0.9813 - top_k_categorical_accuracy: 1.0000
28/92 [========>.....................] - ETA: 4:08 - loss: 0.0755 - accuracy: 0.9819 - top_k_categorical_accuracy: 1.0000
29/92 [========>.....................] - ETA: 4:04 - loss: 0.0751 - accuracy: 0.9815 - top_k_categorical_accuracy: 1.0000
30/92 [========>.....................] - ETA: 4:00 - loss: 0.0795 - accuracy: 0.9800 - top_k_categorical_accuracy: 1.0000
31/92 [=========>....................] - ETA: 3:56 - loss: 0.0792 - accuracy: 0.9807 - top_k_categorical_accuracy: 1.0000
32/92 [=========>....................] - ETA: 3:52 - loss: 0.0792 - accuracy: 0.9803 - top_k_categorical_accuracy: 1.0000
33/92 [=========>....................] - ETA: 3:48 - loss: 0.0783 - accuracy: 0.9809 - top_k_categorical_accuracy: 1.0000
34/92 [==========>...................] - ETA: 3:44 - loss: 0.0786 - accuracy: 0.9805 - top_k_categorical_accuracy: 1.0000
35/92 [==========>...................] - ETA: 3:40 - loss: 0.0772 - accuracy: 0.9811 - top_k_categorical_accuracy: 1.0000
36/92 [==========>...................] - ETA: 3:36 - loss: 0.0766 - accuracy: 0.9816 - top_k_categorical_accuracy: 1.0000
37/92 [==========>...................] - ETA: 3:32 - loss: 0.0762 - accuracy: 0.9813 - top_k_categorical_accuracy: 1.0000
38/92 [===========>..................] - ETA: 3:29 - loss: 0.0752 - accuracy: 0.9818 - top_k_categorical_accuracy: 1.0000
39/92 [===========>..................] - ETA: 3:25 - loss: 0.0761 - accuracy: 0.9806 - top_k_categorical_accuracy: 1.0000
40/92 [===========>..................] - ETA: 3:21 - loss: 0.0748 - accuracy: 0.9811 - top_k_categorical_accuracy: 1.0000
41/92 [============>.................] - ETA: 3:17 - loss: 0.0735 - accuracy: 0.9816 - top_k_categorical_accuracy: 1.0000
42/92 [============>.................] - ETA: 3:13 - loss: 0.0722 - accuracy: 0.9820 - top_k_categorical_accuracy: 1.0000
43/92 [============>.................] - ETA: 3:09 - loss: 0.0721 - accuracy: 0.9824 - top_k_categorical_accuracy: 1.0000
44/92 [=============>................] - ETA: 3:05 - loss: 0.0750 - accuracy: 0.9814 - top_k_categorical_accuracy: 1.0000
45/92 [=============>................] - ETA: 3:01 - loss: 0.0747 - accuracy: 0.9811 - top_k_categorical_accuracy: 1.0000
46/92 [=============>................] - ETA: 2:58 - loss: 0.0735 - accuracy: 0.9815 - top_k_categorical_accuracy: 1.0000
47/92 [==============>...............] - ETA: 2:54 - loss: 0.0724 - accuracy: 0.9819 - top_k_categorical_accuracy: 1.0000
48/92 [==============>...............] - ETA: 2:50 - loss: 0.0717 - accuracy: 0.9823 - top_k_categorical_accuracy: 1.0000
49/92 [==============>...............] - ETA: 2:46 - loss: 0.0712 - accuracy: 0.9827 - top_k_categorical_accuracy: 1.0000
50/92 [===============>..............] - ETA: 2:42 - loss: 0.0786 - accuracy: 0.9792 - top_k_categorical_accuracy: 1.0000
51/92 [===============>..............] - ETA: 2:38 - loss: 0.0815 - accuracy: 0.9778 - top_k_categorical_accuracy: 1.0000
52/92 [===============>..............] - ETA: 2:35 - loss: 0.0807 - accuracy: 0.9782 - top_k_categorical_accuracy: 1.0000
53/92 [================>.............] - ETA: 2:31 - loss: 0.0797 - accuracy: 0.9786 - top_k_categorical_accuracy: 1.0000
54/92 [================>.............] - ETA: 2:27 - loss: 0.0806 - accuracy: 0.9779 - top_k_categorical_accuracy: 1.0000
55/92 [================>.............] - ETA: 2:23 - loss: 0.0799 - accuracy: 0.9783 - top_k_categorical_accuracy: 1.0000
56/92 [=================>............] - ETA: 2:19 - loss: 0.0793 - accuracy: 0.9787 - top_k_categorical_accuracy: 1.0000
57/92 [=================>............] - ETA: 2:15 - loss: 0.0789 - accuracy: 0.9791 - top_k_categorical_accuracy: 1.0000
58/92 [=================>............] - ETA: 2:12 - loss: 0.0789 - accuracy: 0.9789 - top_k_categorical_accuracy: 1.0000
59/92 [==================>...........] - ETA: 2:08 - loss: 0.0800 - accuracy: 0.9782 - top_k_categorical_accuracy: 1.0000
60/92 [==================>...........] - ETA: 2:04 - loss: 0.0791 - accuracy: 0.9785 - top_k_categorical_accuracy: 1.0000
61/92 [==================>...........] - ETA: 2:00 - loss: 0.0787 - accuracy: 0.9789 - top_k_categorical_accuracy: 1.0000
62/92 [===================>..........] - ETA: 1:56 - loss: 0.0788 - accuracy: 0.9792 - top_k_categorical_accuracy: 1.0000
63/92 [===================>..........] - ETA: 1:52 - loss: 0.0785 - accuracy: 0.9791 - top_k_categorical_accuracy: 1.0000
64/92 [===================>..........] - ETA: 1:49 - loss: 0.0776 - accuracy: 0.9794 - top_k_categorical_accuracy: 1.0000
65/92 [====================>.........] - ETA: 1:45 - loss: 0.0778 - accuracy: 0.9792 - top_k_categorical_accuracy: 1.0000
66/92 [====================>.........] - ETA: 1:41 - loss: 0.0770 - accuracy: 0.9795 - top_k_categorical_accuracy: 1.0000
67/92 [====================>.........] - ETA: 1:37 - loss: 0.0772 - accuracy: 0.9794 - top_k_categorical_accuracy: 1.0000
68/92 [=====================>........] - ETA: 1:33 - loss: 0.0784 - accuracy: 0.9792 - top_k_categorical_accuracy: 1.0000
69/92 [=====================>........] - ETA: 1:30 - loss: 0.0779 - accuracy: 0.9795 - top_k_categorical_accuracy: 1.0000
70/92 [=====================>........] - ETA: 1:26 - loss: 0.0771 - accuracy: 0.9798 - top_k_categorical_accuracy: 1.0000
71/92 [=====================>........] - ETA: 1:22 - loss: 0.0764 - accuracy: 0.9801 - top_k_categorical_accuracy: 1.0000
72/92 [======================>.......] - ETA: 1:18 - loss: 0.0758 - accuracy: 0.9804 - top_k_categorical_accuracy: 1.0000
73/92 [======================>.......] - ETA: 1:14 - loss: 0.0755 - accuracy: 0.9807 - top_k_categorical_accuracy: 1.0000
74/92 [======================>.......] - ETA: 1:11 - loss: 0.0751 - accuracy: 0.9809 - top_k_categorical_accuracy: 1.0000
75/92 [=======================>......] - ETA: 1:07 - loss: 0.0744 - accuracy: 0.9812 - top_k_categorical_accuracy: 1.0000
76/92 [=======================>......] - ETA: 1:03 - loss: 0.0742 - accuracy: 0.9810 - top_k_categorical_accuracy: 1.0000
77/92 [=======================>......] - ETA: 59s - loss: 0.0740 - accuracy: 0.9813 - top_k_categorical_accuracy: 1.0000 
78/92 [========================>.....] - ETA: 56s - loss: 0.0734 - accuracy: 0.9815 - top_k_categorical_accuracy: 1.0000
79/92 [========================>.....] - ETA: 52s - loss: 0.0734 - accuracy: 0.9817 - top_k_categorical_accuracy: 1.0000
80/92 [========================>.....] - ETA: 48s - loss: 0.0729 - accuracy: 0.9820 - top_k_categorical_accuracy: 1.0000
81/92 [=========================>....] - ETA: 45s - loss: 0.0725 - accuracy: 0.9822 - top_k_categorical_accuracy: 1.0000
82/92 [=========================>....] - ETA: 41s - loss: 0.0719 - accuracy: 0.9824 - top_k_categorical_accuracy: 1.0000
83/92 [=========================>....] - ETA: 37s - loss: 0.0712 - accuracy: 0.9826 - top_k_categorical_accuracy: 1.0000
84/92 [==========================>...] - ETA: 34s - loss: 0.0710 - accuracy: 0.9828 - top_k_categorical_accuracy: 1.0000
85/92 [==========================>...] - ETA: 30s - loss: 0.0714 - accuracy: 0.9830 - top_k_categorical_accuracy: 1.0000
86/92 [==========================>...] - ETA: 26s - loss: 0.0711 - accuracy: 0.9829 - top_k_categorical_accuracy: 1.0000
87/92 [===========================>..] - ETA: 22s - loss: 0.0705 - accuracy: 0.9831 - top_k_categorical_accuracy: 1.0000
88/92 [===========================>..] - ETA: 18s - loss: 0.0703 - accuracy: 0.9833 - top_k_categorical_accuracy: 1.0000
89/92 [===========================>..] - ETA: 14s - loss: 0.0699 - accuracy: 0.9834 - top_k_categorical_accuracy: 1.0000
90/92 [============================>.] - ETA: 10s - loss: 0.0696 - accuracy: 0.9836 - top_k_categorical_accuracy: 1.0000
91/92 [============================>.] - ETA: 6s - loss: 0.0690 - accuracy: 0.9838 - top_k_categorical_accuracy: 1.0000 
92/92 [============================>.] - ETA: 2s - loss: 0.0686 - accuracy: 0.9840 - top_k_categorical_accuracy: 1.0000
93/92 [==============================] - 496s 5s/step - loss: 0.0682 - accuracy: 0.9842 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.5899 - val_accuracy: 0.6866 - val_top_k_categorical_accuracy: 1.0000
Epoch 6/10

 1/92 [..............................] - ETA: 5:49 - loss: 0.0342 - accuracy: 0.9688 - top_k_categorical_accuracy: 1.0000
 2/92 [..............................] - ETA: 5:40 - loss: 0.0378 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000
 3/92 [..............................] - ETA: 5:34 - loss: 0.0423 - accuracy: 0.9792 - top_k_categorical_accuracy: 1.0000
 4/92 [>.............................] - ETA: 5:30 - loss: 0.0407 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000
 5/92 [>.............................] - ETA: 5:24 - loss: 0.0563 - accuracy: 0.9812 - top_k_categorical_accuracy: 1.0000
 6/92 [>.............................] - ETA: 5:20 - loss: 0.0530 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000
 7/92 [=>............................] - ETA: 5:16 - loss: 0.0516 - accuracy: 0.9821 - top_k_categorical_accuracy: 1.0000
 8/92 [=>............................] - ETA: 5:12 - loss: 0.0507 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000
 9/92 [=>............................] - ETA: 5:08 - loss: 0.0475 - accuracy: 0.9861 - top_k_categorical_accuracy: 1.0000
10/92 [==>...........................] - ETA: 5:04 - loss: 0.0463 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000
11/92 [==>...........................] - ETA: 5:01 - loss: 0.0588 - accuracy: 0.9801 - top_k_categorical_accuracy: 1.0000
12/92 [==>...........................] - ETA: 4:57 - loss: 0.0557 - accuracy: 0.9818 - top_k_categorical_accuracy: 1.0000
13/92 [===>..........................] - ETA: 4:53 - loss: 0.0530 - accuracy: 0.9832 - top_k_categorical_accuracy: 1.0000
14/92 [===>..........................] - ETA: 4:49 - loss: 0.0549 - accuracy: 0.9821 - top_k_categorical_accuracy: 1.0000
15/92 [===>..........................] - ETA: 4:46 - loss: 0.0545 - accuracy: 0.9833 - top_k_categorical_accuracy: 1.0000
16/92 [====>.........................] - ETA: 4:42 - loss: 0.0554 - accuracy: 0.9824 - top_k_categorical_accuracy: 1.0000
17/92 [====>.........................] - ETA: 4:38 - loss: 0.0530 - accuracy: 0.9835 - top_k_categorical_accuracy: 1.0000
18/92 [====>.........................] - ETA: 4:34 - loss: 0.0614 - accuracy: 0.9809 - top_k_categorical_accuracy: 1.0000
19/92 [=====>........................] - ETA: 4:31 - loss: 0.0773 - accuracy: 0.9737 - top_k_categorical_accuracy: 1.0000
20/92 [=====>........................] - ETA: 4:27 - loss: 0.0827 - accuracy: 0.9719 - top_k_categorical_accuracy: 1.0000
21/92 [=====>........................] - ETA: 4:23 - loss: 0.0799 - accuracy: 0.9732 - top_k_categorical_accuracy: 1.0000
22/92 [======>.......................] - ETA: 4:19 - loss: 0.0799 - accuracy: 0.9730 - top_k_categorical_accuracy: 1.0000
23/92 [======>.......................] - ETA: 4:16 - loss: 0.0792 - accuracy: 0.9742 - top_k_categorical_accuracy: 1.0000
24/92 [======>.......................] - ETA: 4:12 - loss: 0.0775 - accuracy: 0.9753 - top_k_categorical_accuracy: 1.0000
25/92 [=======>......................] - ETA: 4:08 - loss: 0.0769 - accuracy: 0.9750 - top_k_categorical_accuracy: 1.0000
26/92 [=======>......................] - ETA: 4:04 - loss: 0.0754 - accuracy: 0.9760 - top_k_categorical_accuracy: 1.0000
27/92 [=======>......................] - ETA: 4:01 - loss: 0.0813 - accuracy: 0.9734 - top_k_categorical_accuracy: 1.0000
28/92 [========>.....................] - ETA: 3:57 - loss: 0.0794 - accuracy: 0.9743 - top_k_categorical_accuracy: 1.0000
29/92 [========>.....................] - ETA: 3:53 - loss: 0.0789 - accuracy: 0.9741 - top_k_categorical_accuracy: 1.0000
30/92 [========>.....................] - ETA: 3:50 - loss: 0.0792 - accuracy: 0.9740 - top_k_categorical_accuracy: 1.0000
31/92 [=========>....................] - ETA: 3:46 - loss: 0.0783 - accuracy: 0.9748 - top_k_categorical_accuracy: 1.0000
32/92 [=========>....................] - ETA: 3:42 - loss: 0.0770 - accuracy: 0.9756 - top_k_categorical_accuracy: 1.0000
33/92 [=========>....................] - ETA: 3:39 - loss: 0.0753 - accuracy: 0.9763 - top_k_categorical_accuracy: 1.0000
34/92 [==========>...................] - ETA: 3:35 - loss: 0.0755 - accuracy: 0.9770 - top_k_categorical_accuracy: 1.0000
35/92 [==========>...................] - ETA: 3:31 - loss: 0.0743 - accuracy: 0.9777 - top_k_categorical_accuracy: 1.0000
36/92 [==========>...................] - ETA: 3:27 - loss: 0.0731 - accuracy: 0.9783 - top_k_categorical_accuracy: 1.0000
37/92 [==========>...................] - ETA: 3:24 - loss: 0.0717 - accuracy: 0.9789 - top_k_categorical_accuracy: 1.0000
38/92 [===========>..................] - ETA: 3:20 - loss: 0.0715 - accuracy: 0.9794 - top_k_categorical_accuracy: 1.0000
39/92 [===========>..................] - ETA: 3:16 - loss: 0.0709 - accuracy: 0.9800 - top_k_categorical_accuracy: 1.0000
40/92 [===========>..................] - ETA: 3:13 - loss: 0.0700 - accuracy: 0.9805 - top_k_categorical_accuracy: 1.0000
41/92 [============>.................] - ETA: 3:09 - loss: 0.0688 - accuracy: 0.9809 - top_k_categorical_accuracy: 1.0000
42/92 [============>.................] - ETA: 3:05 - loss: 0.0677 - accuracy: 0.9814 - top_k_categorical_accuracy: 1.0000
43/92 [============>.................] - ETA: 3:02 - loss: 0.0666 - accuracy: 0.9818 - top_k_categorical_accuracy: 1.0000
44/92 [=============>................] - ETA: 2:58 - loss: 0.0659 - accuracy: 0.9822 - top_k_categorical_accuracy: 1.0000
45/92 [=============>................] - ETA: 2:55 - loss: 0.0664 - accuracy: 0.9812 - top_k_categorical_accuracy: 1.0000
46/92 [=============>................] - ETA: 2:51 - loss: 0.0656 - accuracy: 0.9817 - top_k_categorical_accuracy: 1.0000
47/92 [==============>...............] - ETA: 2:48 - loss: 0.0653 - accuracy: 0.9820 - top_k_categorical_accuracy: 1.0000
48/92 [==============>...............] - ETA: 2:44 - loss: 0.0646 - accuracy: 0.9824 - top_k_categorical_accuracy: 1.0000
49/92 [==============>...............] - ETA: 2:40 - loss: 0.0637 - accuracy: 0.9828 - top_k_categorical_accuracy: 1.0000
50/92 [===============>..............] - ETA: 2:37 - loss: 0.0661 - accuracy: 0.9812 - top_k_categorical_accuracy: 1.0000
51/92 [===============>..............] - ETA: 2:33 - loss: 0.0658 - accuracy: 0.9810 - top_k_categorical_accuracy: 1.0000
52/92 [===============>..............] - ETA: 2:29 - loss: 0.0650 - accuracy: 0.9814 - top_k_categorical_accuracy: 1.0000
53/92 [================>.............] - ETA: 2:26 - loss: 0.0652 - accuracy: 0.9811 - top_k_categorical_accuracy: 1.0000
54/92 [================>.............] - ETA: 2:22 - loss: 0.0658 - accuracy: 0.9815 - top_k_categorical_accuracy: 1.0000
55/92 [================>.............] - ETA: 2:19 - loss: 0.0655 - accuracy: 0.9818 - top_k_categorical_accuracy: 1.0000
56/92 [=================>............] - ETA: 2:15 - loss: 0.0658 - accuracy: 0.9810 - top_k_categorical_accuracy: 1.0000
57/92 [=================>............] - ETA: 2:11 - loss: 0.0652 - accuracy: 0.9814 - top_k_categorical_accuracy: 1.0000
58/92 [=================>............] - ETA: 2:08 - loss: 0.0648 - accuracy: 0.9817 - top_k_categorical_accuracy: 1.0000
59/92 [==================>...........] - ETA: 2:04 - loss: 0.0641 - accuracy: 0.9820 - top_k_categorical_accuracy: 1.0000
60/92 [==================>...........] - ETA: 2:00 - loss: 0.0634 - accuracy: 0.9823 - top_k_categorical_accuracy: 1.0000
61/92 [==================>...........] - ETA: 1:56 - loss: 0.0627 - accuracy: 0.9825 - top_k_categorical_accuracy: 1.0000
62/92 [===================>..........] - ETA: 1:52 - loss: 0.0623 - accuracy: 0.9828 - top_k_categorical_accuracy: 1.0000
63/92 [===================>..........] - ETA: 1:49 - loss: 0.0618 - accuracy: 0.9831 - top_k_categorical_accuracy: 1.0000
64/92 [===================>..........] - ETA: 1:45 - loss: 0.0613 - accuracy: 0.9833 - top_k_categorical_accuracy: 1.0000
65/92 [====================>.........] - ETA: 1:41 - loss: 0.0607 - accuracy: 0.9836 - top_k_categorical_accuracy: 1.0000
66/92 [====================>.........] - ETA: 1:38 - loss: 0.0602 - accuracy: 0.9838 - top_k_categorical_accuracy: 1.0000
67/92 [====================>.........] - ETA: 1:34 - loss: 0.0597 - accuracy: 0.9841 - top_k_categorical_accuracy: 1.0000
68/92 [=====================>........] - ETA: 1:30 - loss: 0.0642 - accuracy: 0.9811 - top_k_categorical_accuracy: 1.0000
69/92 [=====================>........] - ETA: 1:27 - loss: 0.0641 - accuracy: 0.9809 - top_k_categorical_accuracy: 1.0000
70/92 [=====================>........] - ETA: 1:23 - loss: 0.0657 - accuracy: 0.9803 - top_k_categorical_accuracy: 1.0000
71/92 [=====================>........] - ETA: 1:19 - loss: 0.0651 - accuracy: 0.9805 - top_k_categorical_accuracy: 1.0000
72/92 [======================>.......] - ETA: 1:16 - loss: 0.0646 - accuracy: 0.9808 - top_k_categorical_accuracy: 1.0000
73/92 [======================>.......] - ETA: 1:12 - loss: 0.0641 - accuracy: 0.9811 - top_k_categorical_accuracy: 1.0000
74/92 [======================>.......] - ETA: 1:08 - loss: 0.0635 - accuracy: 0.9813 - top_k_categorical_accuracy: 1.0000
75/92 [=======================>......] - ETA: 1:05 - loss: 0.0631 - accuracy: 0.9816 - top_k_categorical_accuracy: 1.0000
76/92 [=======================>......] - ETA: 1:01 - loss: 0.0629 - accuracy: 0.9818 - top_k_categorical_accuracy: 1.0000
77/92 [=======================>......] - ETA: 57s - loss: 0.0634 - accuracy: 0.9817 - top_k_categorical_accuracy: 1.0000 
78/92 [========================>.....] - ETA: 54s - loss: 0.0629 - accuracy: 0.9819 - top_k_categorical_accuracy: 1.0000
79/92 [========================>.....] - ETA: 50s - loss: 0.0630 - accuracy: 0.9817 - top_k_categorical_accuracy: 1.0000
80/92 [========================>.....] - ETA: 46s - loss: 0.0630 - accuracy: 0.9820 - top_k_categorical_accuracy: 1.0000
81/92 [=========================>....] - ETA: 43s - loss: 0.0629 - accuracy: 0.9818 - top_k_categorical_accuracy: 1.0000
82/92 [=========================>....] - ETA: 39s - loss: 0.0625 - accuracy: 0.9820 - top_k_categorical_accuracy: 1.0000
83/92 [=========================>....] - ETA: 35s - loss: 0.0622 - accuracy: 0.9822 - top_k_categorical_accuracy: 1.0000
84/92 [==========================>...] - ETA: 32s - loss: 0.0616 - accuracy: 0.9824 - top_k_categorical_accuracy: 1.0000
85/92 [==========================>...] - ETA: 28s - loss: 0.0614 - accuracy: 0.9827 - top_k_categorical_accuracy: 1.0000
86/92 [==========================>...] - ETA: 24s - loss: 0.0609 - accuracy: 0.9829 - top_k_categorical_accuracy: 1.0000
87/92 [===========================>..] - ETA: 21s - loss: 0.0604 - accuracy: 0.9831 - top_k_categorical_accuracy: 1.0000
88/92 [===========================>..] - ETA: 17s - loss: 0.0599 - accuracy: 0.9833 - top_k_categorical_accuracy: 1.0000
89/92 [===========================>..] - ETA: 13s - loss: 0.0612 - accuracy: 0.9827 - top_k_categorical_accuracy: 1.0000
90/92 [============================>.] - ETA: 9s - loss: 0.0614 - accuracy: 0.9826 - top_k_categorical_accuracy: 1.0000 
91/92 [============================>.] - ETA: 6s - loss: 0.0611 - accuracy: 0.9828 - top_k_categorical_accuracy: 1.0000
92/92 [============================>.] - ETA: 2s - loss: 0.0609 - accuracy: 0.9830 - top_k_categorical_accuracy: 1.0000
93/92 [==============================] - 489s 5s/step - loss: 0.0610 - accuracy: 0.9831 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0215 - val_accuracy: 0.5895 - val_top_k_categorical_accuracy: 1.0000
Epoch 7/10

 1/92 [..............................] - ETA: 6:09 - loss: 0.0648 - accuracy: 0.9688 - top_k_categorical_accuracy: 1.0000
 2/92 [..............................] - ETA: 6:00 - loss: 0.0499 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000
 3/92 [..............................] - ETA: 5:51 - loss: 0.0474 - accuracy: 0.9896 - top_k_categorical_accuracy: 1.0000
 4/92 [>.............................] - ETA: 5:42 - loss: 0.0394 - accuracy: 0.9922 - top_k_categorical_accuracy: 1.0000
 5/92 [>.............................] - ETA: 5:36 - loss: 0.0366 - accuracy: 0.9937 - top_k_categorical_accuracy: 1.0000
 6/92 [>.............................] - ETA: 5:31 - loss: 0.0333 - accuracy: 0.9948 - top_k_categorical_accuracy: 1.0000
 7/92 [=>............................] - ETA: 5:27 - loss: 0.0337 - accuracy: 0.9955 - top_k_categorical_accuracy: 1.0000
 8/92 [=>............................] - ETA: 5:21 - loss: 0.0312 - accuracy: 0.9961 - top_k_categorical_accuracy: 1.0000
 9/92 [=>............................] - ETA: 5:16 - loss: 0.0309 - accuracy: 0.9965 - top_k_categorical_accuracy: 1.0000
10/92 [==>...........................] - ETA: 5:12 - loss: 0.0297 - accuracy: 0.9969 - top_k_categorical_accuracy: 1.0000
11/92 [==>...........................] - ETA: 5:07 - loss: 0.0307 - accuracy: 0.9972 - top_k_categorical_accuracy: 1.0000
12/92 [==>...........................] - ETA: 5:04 - loss: 0.0294 - accuracy: 0.9974 - top_k_categorical_accuracy: 1.0000
13/92 [===>..........................] - ETA: 5:00 - loss: 0.0314 - accuracy: 0.9976 - top_k_categorical_accuracy: 1.0000
14/92 [===>..........................] - ETA: 4:56 - loss: 0.0369 - accuracy: 0.9955 - top_k_categorical_accuracy: 1.0000
15/92 [===>..........................] - ETA: 4:52 - loss: 0.0364 - accuracy: 0.9958 - top_k_categorical_accuracy: 1.0000
16/92 [====>.........................] - ETA: 4:48 - loss: 0.0347 - accuracy: 0.9961 - top_k_categorical_accuracy: 1.0000
17/92 [====>.........................] - ETA: 4:45 - loss: 0.0351 - accuracy: 0.9963 - top_k_categorical_accuracy: 1.0000
18/92 [====>.........................] - ETA: 4:41 - loss: 0.0339 - accuracy: 0.9965 - top_k_categorical_accuracy: 1.0000
19/92 [=====>........................] - ETA: 4:37 - loss: 0.0337 - accuracy: 0.9967 - top_k_categorical_accuracy: 1.0000
20/92 [=====>........................] - ETA: 4:33 - loss: 0.0345 - accuracy: 0.9969 - top_k_categorical_accuracy: 1.0000
21/92 [=====>........................] - ETA: 4:30 - loss: 0.0395 - accuracy: 0.9940 - top_k_categorical_accuracy: 1.0000
22/92 [======>.......................] - ETA: 4:26 - loss: 0.0404 - accuracy: 0.9943 - top_k_categorical_accuracy: 1.0000
23/92 [======>.......................] - ETA: 4:22 - loss: 0.0408 - accuracy: 0.9946 - top_k_categorical_accuracy: 1.0000
24/92 [======>.......................] - ETA: 4:18 - loss: 0.0428 - accuracy: 0.9935 - top_k_categorical_accuracy: 1.0000
25/92 [=======>......................] - ETA: 4:14 - loss: 0.0420 - accuracy: 0.9937 - top_k_categorical_accuracy: 1.0000
26/92 [=======>......................] - ETA: 4:11 - loss: 0.0415 - accuracy: 0.9940 - top_k_categorical_accuracy: 1.0000
27/92 [=======>......................] - ETA: 4:08 - loss: 0.0404 - accuracy: 0.9942 - top_k_categorical_accuracy: 1.0000
28/92 [========>.....................] - ETA: 4:04 - loss: 0.0403 - accuracy: 0.9944 - top_k_categorical_accuracy: 1.0000
29/92 [========>.....................] - ETA: 4:00 - loss: 0.0414 - accuracy: 0.9946 - top_k_categorical_accuracy: 1.0000
30/92 [========>.....................] - ETA: 3:57 - loss: 0.0414 - accuracy: 0.9948 - top_k_categorical_accuracy: 1.0000
31/92 [=========>....................] - ETA: 3:53 - loss: 0.0405 - accuracy: 0.9950 - top_k_categorical_accuracy: 1.0000
32/92 [=========>....................] - ETA: 3:49 - loss: 0.0395 - accuracy: 0.9951 - top_k_categorical_accuracy: 1.0000
33/92 [=========>....................] - ETA: 3:43 - loss: 0.0394 - accuracy: 0.9952 - top_k_categorical_accuracy: 1.0000
34/92 [==========>...................] - ETA: 3:40 - loss: 0.0391 - accuracy: 0.9954 - top_k_categorical_accuracy: 1.0000
35/92 [==========>...................] - ETA: 3:36 - loss: 0.0389 - accuracy: 0.9955 - top_k_categorical_accuracy: 1.0000
36/92 [==========>...................] - ETA: 3:32 - loss: 0.0398 - accuracy: 0.9947 - top_k_categorical_accuracy: 1.0000
37/92 [==========>...................] - ETA: 3:28 - loss: 0.0406 - accuracy: 0.9940 - top_k_categorical_accuracy: 1.0000
38/92 [===========>..................] - ETA: 3:25 - loss: 0.0397 - accuracy: 0.9942 - top_k_categorical_accuracy: 1.0000
39/92 [===========>..................] - ETA: 3:21 - loss: 0.0393 - accuracy: 0.9943 - top_k_categorical_accuracy: 1.0000
40/92 [===========>..................] - ETA: 3:17 - loss: 0.0387 - accuracy: 0.9945 - top_k_categorical_accuracy: 1.0000
41/92 [============>.................] - ETA: 3:13 - loss: 0.0431 - accuracy: 0.9923 - top_k_categorical_accuracy: 1.0000
42/92 [============>.................] - ETA: 3:10 - loss: 0.0426 - accuracy: 0.9925 - top_k_categorical_accuracy: 1.0000
43/92 [============>.................] - ETA: 3:06 - loss: 0.0425 - accuracy: 0.9927 - top_k_categorical_accuracy: 1.0000
44/92 [=============>................] - ETA: 3:02 - loss: 0.0424 - accuracy: 0.9928 - top_k_categorical_accuracy: 1.0000
45/92 [=============>................] - ETA: 2:59 - loss: 0.0418 - accuracy: 0.9930 - top_k_categorical_accuracy: 1.0000
46/92 [=============>................] - ETA: 2:55 - loss: 0.0416 - accuracy: 0.9932 - top_k_categorical_accuracy: 1.0000
47/92 [==============>...............] - ETA: 2:51 - loss: 0.0412 - accuracy: 0.9933 - top_k_categorical_accuracy: 1.0000
48/92 [==============>...............] - ETA: 2:47 - loss: 0.0406 - accuracy: 0.9934 - top_k_categorical_accuracy: 1.0000
49/92 [==============>...............] - ETA: 2:44 - loss: 0.0408 - accuracy: 0.9936 - top_k_categorical_accuracy: 1.0000
50/92 [===============>..............] - ETA: 2:40 - loss: 0.0411 - accuracy: 0.9931 - top_k_categorical_accuracy: 1.0000
51/92 [===============>..............] - ETA: 2:36 - loss: 0.0405 - accuracy: 0.9932 - top_k_categorical_accuracy: 1.0000
52/92 [===============>..............] - ETA: 2:32 - loss: 0.0431 - accuracy: 0.9915 - top_k_categorical_accuracy: 1.0000
53/92 [================>.............] - ETA: 2:29 - loss: 0.0515 - accuracy: 0.9870 - top_k_categorical_accuracy: 1.0000
54/92 [================>.............] - ETA: 2:25 - loss: 0.0509 - accuracy: 0.9872 - top_k_categorical_accuracy: 1.0000
55/92 [================>.............] - ETA: 2:21 - loss: 0.0507 - accuracy: 0.9874 - top_k_categorical_accuracy: 1.0000
56/92 [=================>............] - ETA: 2:17 - loss: 0.0509 - accuracy: 0.9871 - top_k_categorical_accuracy: 1.0000
57/92 [=================>............] - ETA: 2:14 - loss: 0.0508 - accuracy: 0.9873 - top_k_categorical_accuracy: 1.0000
58/92 [=================>............] - ETA: 2:10 - loss: 0.0509 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000
59/92 [==================>...........] - ETA: 2:07 - loss: 0.0503 - accuracy: 0.9878 - top_k_categorical_accuracy: 1.0000
60/92 [==================>...........] - ETA: 2:04 - loss: 0.0501 - accuracy: 0.9880 - top_k_categorical_accuracy: 1.0000
61/92 [==================>...........] - ETA: 2:01 - loss: 0.0498 - accuracy: 0.9882 - top_k_categorical_accuracy: 1.0000
62/92 [===================>..........] - ETA: 1:57 - loss: 0.0508 - accuracy: 0.9873 - top_k_categorical_accuracy: 1.0000
63/92 [===================>..........] - ETA: 1:54 - loss: 0.0504 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000
64/92 [===================>..........] - ETA: 1:51 - loss: 0.0501 - accuracy: 0.9877 - top_k_categorical_accuracy: 1.0000
65/92 [====================>.........] - ETA: 1:48 - loss: 0.0502 - accuracy: 0.9874 - top_k_categorical_accuracy: 1.0000
66/92 [====================>.........] - ETA: 1:44 - loss: 0.0505 - accuracy: 0.9872 - top_k_categorical_accuracy: 1.0000
67/92 [====================>.........] - ETA: 1:41 - loss: 0.0502 - accuracy: 0.9873 - top_k_categorical_accuracy: 1.0000
68/92 [=====================>........] - ETA: 1:37 - loss: 0.0498 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000
69/92 [=====================>........] - ETA: 1:34 - loss: 0.0495 - accuracy: 0.9877 - top_k_categorical_accuracy: 1.0000
70/92 [=====================>........] - ETA: 1:30 - loss: 0.0490 - accuracy: 0.9879 - top_k_categorical_accuracy: 1.0000
71/92 [=====================>........] - ETA: 1:27 - loss: 0.0490 - accuracy: 0.9881 - top_k_categorical_accuracy: 1.0000
72/92 [======================>.......] - ETA: 1:23 - loss: 0.0498 - accuracy: 0.9878 - top_k_categorical_accuracy: 1.0000
73/92 [======================>.......] - ETA: 1:19 - loss: 0.0506 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000
74/92 [======================>.......] - ETA: 1:16 - loss: 0.0505 - accuracy: 0.9877 - top_k_categorical_accuracy: 1.0000
75/92 [=======================>......] - ETA: 1:12 - loss: 0.0506 - accuracy: 0.9874 - top_k_categorical_accuracy: 1.0000
76/92 [=======================>......] - ETA: 1:08 - loss: 0.0502 - accuracy: 0.9876 - top_k_categorical_accuracy: 1.0000
77/92 [=======================>......] - ETA: 1:04 - loss: 0.0501 - accuracy: 0.9878 - top_k_categorical_accuracy: 1.0000
78/92 [========================>.....] - ETA: 1:00 - loss: 0.0503 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000
79/92 [========================>.....] - ETA: 56s - loss: 0.0503 - accuracy: 0.9873 - top_k_categorical_accuracy: 1.0000 
80/92 [========================>.....] - ETA: 51s - loss: 0.0507 - accuracy: 0.9871 - top_k_categorical_accuracy: 1.0000
81/92 [=========================>....] - ETA: 47s - loss: 0.0505 - accuracy: 0.9872 - top_k_categorical_accuracy: 1.0000
82/92 [=========================>....] - ETA: 43s - loss: 0.0501 - accuracy: 0.9874 - top_k_categorical_accuracy: 1.0000
83/92 [=========================>....] - ETA: 39s - loss: 0.0502 - accuracy: 0.9872 - top_k_categorical_accuracy: 1.0000
84/92 [==========================>...] - ETA: 35s - loss: 0.0503 - accuracy: 0.9873 - top_k_categorical_accuracy: 1.0000
85/92 [==========================>...] - ETA: 31s - loss: 0.0502 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000
86/92 [==========================>...] - ETA: 27s - loss: 0.0498 - accuracy: 0.9876 - top_k_categorical_accuracy: 1.0000
87/92 [===========================>..] - ETA: 23s - loss: 0.0496 - accuracy: 0.9877 - top_k_categorical_accuracy: 1.0000
88/92 [===========================>..] - ETA: 19s - loss: 0.0495 - accuracy: 0.9879 - top_k_categorical_accuracy: 1.0000
89/92 [===========================>..] - ETA: 14s - loss: 0.0494 - accuracy: 0.9877 - top_k_categorical_accuracy: 1.0000
90/92 [============================>.] - ETA: 10s - loss: 0.0491 - accuracy: 0.9878 - top_k_categorical_accuracy: 1.0000
91/92 [============================>.] - ETA: 6s - loss: 0.0490 - accuracy: 0.9879 - top_k_categorical_accuracy: 1.0000 
92/92 [============================>.] - ETA: 2s - loss: 0.0488 - accuracy: 0.9881 - top_k_categorical_accuracy: 1.0000
93/92 [==============================] - 495s 5s/step - loss: 0.0489 - accuracy: 0.9882 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.6936 - val_top_k_categorical_accuracy: 1.0000
Epoch 8/10

 1/92 [..............................] - ETA: 5:49 - loss: 0.0335 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 2/92 [..............................] - ETA: 5:38 - loss: 0.0231 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 3/92 [..............................] - ETA: 5:32 - loss: 0.0352 - accuracy: 0.9896 - top_k_categorical_accuracy: 1.0000
 4/92 [>.............................] - ETA: 5:28 - loss: 0.0325 - accuracy: 0.9922 - top_k_categorical_accuracy: 1.0000
 5/92 [>.............................] - ETA: 5:24 - loss: 0.0422 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000
 6/92 [>.............................] - ETA: 5:20 - loss: 0.0443 - accuracy: 0.9896 - top_k_categorical_accuracy: 1.0000
 7/92 [=>............................] - ETA: 5:16 - loss: 0.0399 - accuracy: 0.9911 - top_k_categorical_accuracy: 1.0000
 8/92 [=>............................] - ETA: 5:12 - loss: 0.0503 - accuracy: 0.9883 - top_k_categorical_accuracy: 1.0000
 9/92 [=>............................] - ETA: 5:10 - loss: 0.0540 - accuracy: 0.9826 - top_k_categorical_accuracy: 1.0000
10/92 [==>...........................] - ETA: 5:07 - loss: 0.0546 - accuracy: 0.9812 - top_k_categorical_accuracy: 1.0000
11/92 [==>...........................] - ETA: 5:03 - loss: 0.0524 - accuracy: 0.9830 - top_k_categorical_accuracy: 1.0000
12/92 [==>...........................] - ETA: 5:00 - loss: 0.0499 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000
13/92 [===>..........................] - ETA: 4:57 - loss: 0.0479 - accuracy: 0.9856 - top_k_categorical_accuracy: 1.0000
14/92 [===>..........................] - ETA: 4:54 - loss: 0.0478 - accuracy: 0.9866 - top_k_categorical_accuracy: 1.0000
15/92 [===>..........................] - ETA: 4:50 - loss: 0.0452 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000
16/92 [====>.........................] - ETA: 4:47 - loss: 0.0441 - accuracy: 0.9883 - top_k_categorical_accuracy: 1.0000
17/92 [====>.........................] - ETA: 4:43 - loss: 0.0438 - accuracy: 0.9890 - top_k_categorical_accuracy: 1.0000
18/92 [====>.........................] - ETA: 4:40 - loss: 0.0431 - accuracy: 0.9896 - top_k_categorical_accuracy: 1.0000
19/92 [=====>........................] - ETA: 4:36 - loss: 0.0423 - accuracy: 0.9901 - top_k_categorical_accuracy: 1.0000
20/92 [=====>........................] - ETA: 4:35 - loss: 0.0518 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000
21/92 [=====>........................] - ETA: 4:36 - loss: 0.0517 - accuracy: 0.9881 - top_k_categorical_accuracy: 1.0000
22/92 [======>.......................] - ETA: 4:36 - loss: 0.0506 - accuracy: 0.9886 - top_k_categorical_accuracy: 1.0000
23/92 [======>.......................] - ETA: 4:35 - loss: 0.0505 - accuracy: 0.9891 - top_k_categorical_accuracy: 1.0000
24/92 [======>.......................] - ETA: 4:33 - loss: 0.0529 - accuracy: 0.9883 - top_k_categorical_accuracy: 1.0000
25/92 [=======>......................] - ETA: 4:32 - loss: 0.0523 - accuracy: 0.9887 - top_k_categorical_accuracy: 1.0000
26/92 [=======>......................] - ETA: 4:32 - loss: 0.0508 - accuracy: 0.9892 - top_k_categorical_accuracy: 1.0000
27/92 [=======>......................] - ETA: 4:30 - loss: 0.0503 - accuracy: 0.9896 - top_k_categorical_accuracy: 1.0000
28/92 [========>.....................] - ETA: 4:29 - loss: 0.0501 - accuracy: 0.9900 - top_k_categorical_accuracy: 1.0000
29/92 [========>.....................] - ETA: 4:27 - loss: 0.0497 - accuracy: 0.9892 - top_k_categorical_accuracy: 1.0000
30/92 [========>.....................] - ETA: 4:25 - loss: 0.0485 - accuracy: 0.9896 - top_k_categorical_accuracy: 1.0000
31/92 [=========>....................] - ETA: 4:23 - loss: 0.0477 - accuracy: 0.9899 - top_k_categorical_accuracy: 1.0000
32/92 [=========>....................] - ETA: 4:21 - loss: 0.0468 - accuracy: 0.9902 - top_k_categorical_accuracy: 1.0000
33/92 [=========>....................] - ETA: 4:18 - loss: 0.0467 - accuracy: 0.9905 - top_k_categorical_accuracy: 1.0000
34/92 [==========>...................] - ETA: 4:16 - loss: 0.0468 - accuracy: 0.9908 - top_k_categorical_accuracy: 1.0000
35/92 [==========>...................] - ETA: 4:12 - loss: 0.0459 - accuracy: 0.9911 - top_k_categorical_accuracy: 1.0000
36/92 [==========>...................] - ETA: 4:10 - loss: 0.0450 - accuracy: 0.9913 - top_k_categorical_accuracy: 1.0000
37/92 [==========>...................] - ETA: 4:06 - loss: 0.0466 - accuracy: 0.9907 - top_k_categorical_accuracy: 1.0000
38/92 [===========>..................] - ETA: 4:02 - loss: 0.0536 - accuracy: 0.9885 - top_k_categorical_accuracy: 1.0000
39/92 [===========>..................] - ETA: 3:57 - loss: 0.0531 - accuracy: 0.9888 - top_k_categorical_accuracy: 1.0000
40/92 [===========>..................] - ETA: 3:52 - loss: 0.0528 - accuracy: 0.9891 - top_k_categorical_accuracy: 1.0000
41/92 [============>.................] - ETA: 3:47 - loss: 0.0521 - accuracy: 0.9893 - top_k_categorical_accuracy: 1.0000
42/92 [============>.................] - ETA: 3:41 - loss: 0.0519 - accuracy: 0.9896 - top_k_categorical_accuracy: 1.0000
43/92 [============>.................] - ETA: 3:36 - loss: 0.0511 - accuracy: 0.9898 - top_k_categorical_accuracy: 1.0000
44/92 [=============>................] - ETA: 3:31 - loss: 0.0506 - accuracy: 0.9901 - top_k_categorical_accuracy: 1.0000
45/92 [=============>................] - ETA: 3:26 - loss: 0.0500 - accuracy: 0.9903 - top_k_categorical_accuracy: 1.0000
46/92 [=============>................] - ETA: 3:21 - loss: 0.0493 - accuracy: 0.9905 - top_k_categorical_accuracy: 1.0000
47/92 [==============>...............] - ETA: 3:16 - loss: 0.0487 - accuracy: 0.9907 - top_k_categorical_accuracy: 1.0000
48/92 [==============>...............] - ETA: 3:12 - loss: 0.0486 - accuracy: 0.9902 - top_k_categorical_accuracy: 1.0000
49/92 [==============>...............] - ETA: 3:07 - loss: 0.0482 - accuracy: 0.9904 - top_k_categorical_accuracy: 1.0000
50/92 [===============>..............] - ETA: 3:02 - loss: 0.0479 - accuracy: 0.9906 - top_k_categorical_accuracy: 1.0000
51/92 [===============>..............] - ETA: 2:58 - loss: 0.0478 - accuracy: 0.9908 - top_k_categorical_accuracy: 1.0000
52/92 [===============>..............] - ETA: 2:53 - loss: 0.0473 - accuracy: 0.9910 - top_k_categorical_accuracy: 1.0000
53/92 [================>.............] - ETA: 2:48 - loss: 0.0466 - accuracy: 0.9912 - top_k_categorical_accuracy: 1.0000
54/92 [================>.............] - ETA: 2:44 - loss: 0.0473 - accuracy: 0.9907 - top_k_categorical_accuracy: 1.0000
55/92 [================>.............] - ETA: 2:39 - loss: 0.0467 - accuracy: 0.9909 - top_k_categorical_accuracy: 1.0000
56/92 [=================>............] - ETA: 2:35 - loss: 0.0467 - accuracy: 0.9911 - top_k_categorical_accuracy: 1.0000
57/92 [=================>............] - ETA: 2:30 - loss: 0.0465 - accuracy: 0.9907 - top_k_categorical_accuracy: 1.0000
58/92 [=================>............] - ETA: 2:26 - loss: 0.0462 - accuracy: 0.9908 - top_k_categorical_accuracy: 1.0000
59/92 [==================>...........] - ETA: 2:21 - loss: 0.0462 - accuracy: 0.9905 - top_k_categorical_accuracy: 1.0000
60/92 [==================>...........] - ETA: 2:17 - loss: 0.0460 - accuracy: 0.9906 - top_k_categorical_accuracy: 1.0000
61/92 [==================>...........] - ETA: 2:12 - loss: 0.0457 - accuracy: 0.9908 - top_k_categorical_accuracy: 1.0000
62/92 [===================>..........] - ETA: 2:08 - loss: 0.0460 - accuracy: 0.9899 - top_k_categorical_accuracy: 1.0000
63/92 [===================>..........] - ETA: 2:04 - loss: 0.0456 - accuracy: 0.9901 - top_k_categorical_accuracy: 1.0000
64/92 [===================>..........] - ETA: 1:59 - loss: 0.0452 - accuracy: 0.9902 - top_k_categorical_accuracy: 1.0000
65/92 [====================>.........] - ETA: 1:55 - loss: 0.0449 - accuracy: 0.9904 - top_k_categorical_accuracy: 1.0000
66/92 [====================>.........] - ETA: 1:51 - loss: 0.0445 - accuracy: 0.9905 - top_k_categorical_accuracy: 1.0000
67/92 [====================>.........] - ETA: 1:46 - loss: 0.0441 - accuracy: 0.9907 - top_k_categorical_accuracy: 1.0000
68/92 [=====================>........] - ETA: 1:42 - loss: 0.0444 - accuracy: 0.9903 - top_k_categorical_accuracy: 1.0000
69/92 [=====================>........] - ETA: 1:38 - loss: 0.0438 - accuracy: 0.9905 - top_k_categorical_accuracy: 1.0000
70/92 [=====================>........] - ETA: 1:33 - loss: 0.0441 - accuracy: 0.9897 - top_k_categorical_accuracy: 1.0000
71/92 [=====================>........] - ETA: 1:29 - loss: 0.0446 - accuracy: 0.9890 - top_k_categorical_accuracy: 1.0000
72/92 [======================>.......] - ETA: 1:25 - loss: 0.0448 - accuracy: 0.9891 - top_k_categorical_accuracy: 1.0000
73/92 [======================>.......] - ETA: 1:21 - loss: 0.0450 - accuracy: 0.9889 - top_k_categorical_accuracy: 1.0000
74/92 [======================>.......] - ETA: 1:17 - loss: 0.0504 - accuracy: 0.9865 - top_k_categorical_accuracy: 1.0000
75/92 [=======================>......] - ETA: 1:12 - loss: 0.0505 - accuracy: 0.9862 - top_k_categorical_accuracy: 1.0000
76/92 [=======================>......] - ETA: 1:08 - loss: 0.0506 - accuracy: 0.9860 - top_k_categorical_accuracy: 1.0000
77/92 [=======================>......] - ETA: 1:04 - loss: 0.0501 - accuracy: 0.9862 - top_k_categorical_accuracy: 1.0000
78/92 [========================>.....] - ETA: 1:00 - loss: 0.0496 - accuracy: 0.9864 - top_k_categorical_accuracy: 1.0000
79/92 [========================>.....] - ETA: 56s - loss: 0.0494 - accuracy: 0.9866 - top_k_categorical_accuracy: 1.0000 
80/92 [========================>.....] - ETA: 51s - loss: 0.0492 - accuracy: 0.9867 - top_k_categorical_accuracy: 1.0000
81/92 [=========================>....] - ETA: 47s - loss: 0.0503 - accuracy: 0.9861 - top_k_categorical_accuracy: 1.0000
82/92 [=========================>....] - ETA: 43s - loss: 0.0498 - accuracy: 0.9863 - top_k_categorical_accuracy: 1.0000
83/92 [=========================>....] - ETA: 39s - loss: 0.0495 - accuracy: 0.9864 - top_k_categorical_accuracy: 1.0000
84/92 [==========================>...] - ETA: 35s - loss: 0.0492 - accuracy: 0.9866 - top_k_categorical_accuracy: 1.0000
85/92 [==========================>...] - ETA: 31s - loss: 0.0492 - accuracy: 0.9868 - top_k_categorical_accuracy: 1.0000
86/92 [==========================>...] - ETA: 27s - loss: 0.0502 - accuracy: 0.9865 - top_k_categorical_accuracy: 1.0000
87/92 [===========================>..] - ETA: 23s - loss: 0.0507 - accuracy: 0.9867 - top_k_categorical_accuracy: 1.0000
88/92 [===========================>..] - ETA: 18s - loss: 0.0503 - accuracy: 0.9868 - top_k_categorical_accuracy: 1.0000
89/92 [===========================>..] - ETA: 14s - loss: 0.0500 - accuracy: 0.9870 - top_k_categorical_accuracy: 1.0000
90/92 [============================>.] - ETA: 10s - loss: 0.0496 - accuracy: 0.9871 - top_k_categorical_accuracy: 1.0000
91/92 [============================>.] - ETA: 6s - loss: 0.0505 - accuracy: 0.9869 - top_k_categorical_accuracy: 1.0000 
92/92 [============================>.] - ETA: 2s - loss: 0.0523 - accuracy: 0.9860 - top_k_categorical_accuracy: 1.0000
93/92 [==============================] - 521s 6s/step - loss: 0.0525 - accuracy: 0.9858 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7405 - val_accuracy: 0.6026 - val_top_k_categorical_accuracy: 1.0000
Epoch 9/10

 1/92 [..............................] - ETA: 5:47 - loss: 0.0601 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 2/92 [..............................] - ETA: 5:41 - loss: 0.0589 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 3/92 [..............................] - ETA: 5:37 - loss: 0.0583 - accuracy: 0.9896 - top_k_categorical_accuracy: 1.0000
 4/92 [>.............................] - ETA: 5:33 - loss: 0.0475 - accuracy: 0.9922 - top_k_categorical_accuracy: 1.0000
 5/92 [>.............................] - ETA: 5:29 - loss: 0.0450 - accuracy: 0.9937 - top_k_categorical_accuracy: 1.0000
 6/92 [>.............................] - ETA: 5:24 - loss: 0.0459 - accuracy: 0.9948 - top_k_categorical_accuracy: 1.0000
 7/92 [=>............................] - ETA: 5:20 - loss: 0.0411 - accuracy: 0.9955 - top_k_categorical_accuracy: 1.0000
 8/92 [=>............................] - ETA: 5:16 - loss: 0.0385 - accuracy: 0.9961 - top_k_categorical_accuracy: 1.0000
 9/92 [=>............................] - ETA: 5:12 - loss: 0.0372 - accuracy: 0.9965 - top_k_categorical_accuracy: 1.0000
10/92 [==>...........................] - ETA: 5:09 - loss: 0.0365 - accuracy: 0.9969 - top_k_categorical_accuracy: 1.0000
11/92 [==>...........................] - ETA: 5:06 - loss: 0.0582 - accuracy: 0.9830 - top_k_categorical_accuracy: 1.0000
12/92 [==>...........................] - ETA: 5:02 - loss: 0.0561 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000
13/92 [===>..........................] - ETA: 4:59 - loss: 0.0569 - accuracy: 0.9832 - top_k_categorical_accuracy: 1.0000
14/92 [===>..........................] - ETA: 4:55 - loss: 0.0644 - accuracy: 0.9799 - top_k_categorical_accuracy: 1.0000
15/92 [===>..........................] - ETA: 4:51 - loss: 0.0622 - accuracy: 0.9812 - top_k_categorical_accuracy: 1.0000
16/92 [====>.........................] - ETA: 4:47 - loss: 0.0593 - accuracy: 0.9824 - top_k_categorical_accuracy: 1.0000
17/92 [====>.........................] - ETA: 4:44 - loss: 0.0577 - accuracy: 0.9835 - top_k_categorical_accuracy: 1.0000
18/92 [====>.........................] - ETA: 4:40 - loss: 0.0575 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000
19/92 [=====>........................] - ETA: 4:36 - loss: 0.0557 - accuracy: 0.9852 - top_k_categorical_accuracy: 1.0000
20/92 [=====>........................] - ETA: 4:33 - loss: 0.0549 - accuracy: 0.9859 - top_k_categorical_accuracy: 1.0000
21/92 [=====>........................] - ETA: 4:29 - loss: 0.0533 - accuracy: 0.9866 - top_k_categorical_accuracy: 1.0000
22/92 [======>.......................] - ETA: 4:25 - loss: 0.0519 - accuracy: 0.9872 - top_k_categorical_accuracy: 1.0000
23/92 [======>.......................] - ETA: 4:21 - loss: 0.0502 - accuracy: 0.9878 - top_k_categorical_accuracy: 1.0000
24/92 [======>.......................] - ETA: 4:18 - loss: 0.0525 - accuracy: 0.9870 - top_k_categorical_accuracy: 1.0000
25/92 [=======>......................] - ETA: 4:14 - loss: 0.0540 - accuracy: 0.9850 - top_k_categorical_accuracy: 1.0000
26/92 [=======>......................] - ETA: 4:10 - loss: 0.0551 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000
27/92 [=======>......................] - ETA: 4:06 - loss: 0.0546 - accuracy: 0.9850 - top_k_categorical_accuracy: 1.0000
28/92 [========>.....................] - ETA: 4:03 - loss: 0.0531 - accuracy: 0.9855 - top_k_categorical_accuracy: 1.0000
29/92 [========>.....................] - ETA: 3:59 - loss: 0.0521 - accuracy: 0.9860 - top_k_categorical_accuracy: 1.0000
30/92 [========>.....................] - ETA: 3:55 - loss: 0.0537 - accuracy: 0.9854 - top_k_categorical_accuracy: 1.0000
31/92 [=========>....................] - ETA: 3:51 - loss: 0.0523 - accuracy: 0.9859 - top_k_categorical_accuracy: 1.0000
32/92 [=========>....................] - ETA: 3:48 - loss: 0.0518 - accuracy: 0.9863 - top_k_categorical_accuracy: 1.0000
33/92 [=========>....................] - ETA: 3:44 - loss: 0.0505 - accuracy: 0.9867 - top_k_categorical_accuracy: 1.0000
34/92 [==========>...................] - ETA: 3:40 - loss: 0.0502 - accuracy: 0.9871 - top_k_categorical_accuracy: 1.0000
35/92 [==========>...................] - ETA: 3:36 - loss: 0.0489 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000
36/92 [==========>...................] - ETA: 3:33 - loss: 0.0485 - accuracy: 0.9878 - top_k_categorical_accuracy: 1.0000
37/92 [==========>...................] - ETA: 3:29 - loss: 0.0490 - accuracy: 0.9873 - top_k_categorical_accuracy: 1.0000
38/92 [===========>..................] - ETA: 3:25 - loss: 0.0480 - accuracy: 0.9877 - top_k_categorical_accuracy: 1.0000
39/92 [===========>..................] - ETA: 3:21 - loss: 0.0482 - accuracy: 0.9872 - top_k_categorical_accuracy: 1.0000
40/92 [===========>..................] - ETA: 3:18 - loss: 0.0476 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000
41/92 [============>.................] - ETA: 3:14 - loss: 0.0476 - accuracy: 0.9870 - top_k_categorical_accuracy: 1.0000
42/92 [============>.................] - ETA: 3:10 - loss: 0.0474 - accuracy: 0.9874 - top_k_categorical_accuracy: 1.0000
43/92 [============>.................] - ETA: 3:06 - loss: 0.0470 - accuracy: 0.9876 - top_k_categorical_accuracy: 1.0000
44/92 [=============>................] - ETA: 3:03 - loss: 0.0461 - accuracy: 0.9879 - top_k_categorical_accuracy: 1.0000
45/92 [=============>................] - ETA: 2:59 - loss: 0.0453 - accuracy: 0.9882 - top_k_categorical_accuracy: 1.0000
46/92 [=============>................] - ETA: 2:55 - loss: 0.0445 - accuracy: 0.9885 - top_k_categorical_accuracy: 1.0000
47/92 [==============>...............] - ETA: 2:51 - loss: 0.0483 - accuracy: 0.9860 - top_k_categorical_accuracy: 1.0000
48/92 [==============>...............] - ETA: 2:48 - loss: 0.0476 - accuracy: 0.9863 - top_k_categorical_accuracy: 1.0000
49/92 [==============>...............] - ETA: 2:44 - loss: 0.0475 - accuracy: 0.9866 - top_k_categorical_accuracy: 1.0000
50/92 [===============>..............] - ETA: 2:40 - loss: 0.0478 - accuracy: 0.9862 - top_k_categorical_accuracy: 1.0000
51/92 [===============>..............] - ETA: 2:35 - loss: 0.0475 - accuracy: 0.9864 - top_k_categorical_accuracy: 1.0000
52/92 [===============>..............] - ETA: 2:32 - loss: 0.0472 - accuracy: 0.9867 - top_k_categorical_accuracy: 1.0000
53/92 [================>.............] - ETA: 2:28 - loss: 0.0473 - accuracy: 0.9870 - top_k_categorical_accuracy: 1.0000
54/92 [================>.............] - ETA: 2:24 - loss: 0.0467 - accuracy: 0.9872 - top_k_categorical_accuracy: 1.0000
55/92 [================>.............] - ETA: 2:21 - loss: 0.0465 - accuracy: 0.9874 - top_k_categorical_accuracy: 1.0000
56/92 [=================>............] - ETA: 2:18 - loss: 0.0461 - accuracy: 0.9877 - top_k_categorical_accuracy: 1.0000
57/92 [=================>............] - ETA: 2:15 - loss: 0.0465 - accuracy: 0.9873 - top_k_categorical_accuracy: 1.0000
58/92 [=================>............] - ETA: 2:12 - loss: 0.0463 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000
59/92 [==================>...........] - ETA: 2:09 - loss: 0.0460 - accuracy: 0.9878 - top_k_categorical_accuracy: 1.0000
60/92 [==================>...........] - ETA: 2:05 - loss: 0.0460 - accuracy: 0.9880 - top_k_categorical_accuracy: 1.0000
61/92 [==================>...........] - ETA: 2:02 - loss: 0.0464 - accuracy: 0.9876 - top_k_categorical_accuracy: 1.0000
62/92 [===================>..........] - ETA: 1:59 - loss: 0.0459 - accuracy: 0.9878 - top_k_categorical_accuracy: 1.0000
63/92 [===================>..........] - ETA: 1:56 - loss: 0.0459 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000
64/92 [===================>..........] - ETA: 1:52 - loss: 0.0456 - accuracy: 0.9877 - top_k_categorical_accuracy: 1.0000
65/92 [====================>.........] - ETA: 1:49 - loss: 0.0450 - accuracy: 0.9879 - top_k_categorical_accuracy: 1.0000
66/92 [====================>.........] - ETA: 1:46 - loss: 0.0444 - accuracy: 0.9881 - top_k_categorical_accuracy: 1.0000
67/92 [====================>.........] - ETA: 1:42 - loss: 0.0444 - accuracy: 0.9878 - top_k_categorical_accuracy: 1.0000
68/92 [=====================>........] - ETA: 1:39 - loss: 0.0439 - accuracy: 0.9880 - top_k_categorical_accuracy: 1.0000
69/92 [=====================>........] - ETA: 1:35 - loss: 0.0435 - accuracy: 0.9882 - top_k_categorical_accuracy: 1.0000
70/92 [=====================>........] - ETA: 1:31 - loss: 0.0432 - accuracy: 0.9883 - top_k_categorical_accuracy: 1.0000
71/92 [=====================>........] - ETA: 1:28 - loss: 0.0428 - accuracy: 0.9885 - top_k_categorical_accuracy: 1.0000
72/92 [======================>.......] - ETA: 1:24 - loss: 0.0426 - accuracy: 0.9887 - top_k_categorical_accuracy: 1.0000
73/92 [======================>.......] - ETA: 1:20 - loss: 0.0426 - accuracy: 0.9884 - top_k_categorical_accuracy: 1.0000
74/92 [======================>.......] - ETA: 1:16 - loss: 0.0423 - accuracy: 0.9885 - top_k_categorical_accuracy: 1.0000
75/92 [=======================>......] - ETA: 1:12 - loss: 0.0419 - accuracy: 0.9887 - top_k_categorical_accuracy: 1.0000
76/92 [=======================>......] - ETA: 1:08 - loss: 0.0417 - accuracy: 0.9889 - top_k_categorical_accuracy: 1.0000
77/92 [=======================>......] - ETA: 1:04 - loss: 0.0426 - accuracy: 0.9890 - top_k_categorical_accuracy: 1.0000
78/92 [========================>.....] - ETA: 59s - loss: 0.0422 - accuracy: 0.9891 - top_k_categorical_accuracy: 1.0000 
79/92 [========================>.....] - ETA: 55s - loss: 0.0440 - accuracy: 0.9881 - top_k_categorical_accuracy: 1.0000
80/92 [========================>.....] - ETA: 51s - loss: 0.0436 - accuracy: 0.9882 - top_k_categorical_accuracy: 1.0000
81/92 [=========================>....] - ETA: 47s - loss: 0.0432 - accuracy: 0.9884 - top_k_categorical_accuracy: 1.0000
82/92 [=========================>....] - ETA: 43s - loss: 0.0428 - accuracy: 0.9885 - top_k_categorical_accuracy: 1.0000
83/92 [=========================>....] - ETA: 39s - loss: 0.0432 - accuracy: 0.9883 - top_k_categorical_accuracy: 1.0000
84/92 [==========================>...] - ETA: 35s - loss: 0.0434 - accuracy: 0.9884 - top_k_categorical_accuracy: 1.0000
85/92 [==========================>...] - ETA: 31s - loss: 0.0431 - accuracy: 0.9886 - top_k_categorical_accuracy: 1.0000
86/92 [==========================>...] - ETA: 27s - loss: 0.0428 - accuracy: 0.9887 - top_k_categorical_accuracy: 1.0000
87/92 [===========================>..] - ETA: 22s - loss: 0.0454 - accuracy: 0.9877 - top_k_categorical_accuracy: 1.0000
88/92 [===========================>..] - ETA: 18s - loss: 0.0465 - accuracy: 0.9872 - top_k_categorical_accuracy: 1.0000
89/92 [===========================>..] - ETA: 14s - loss: 0.0472 - accuracy: 0.9863 - top_k_categorical_accuracy: 1.0000
90/92 [============================>.] - ETA: 10s - loss: 0.0468 - accuracy: 0.9864 - top_k_categorical_accuracy: 1.0000
91/92 [============================>.] - ETA: 6s - loss: 0.0475 - accuracy: 0.9862 - top_k_categorical_accuracy: 1.0000 
92/92 [============================>.] - ETA: 2s - loss: 0.0472 - accuracy: 0.9864 - top_k_categorical_accuracy: 1.0000
93/92 [==============================] - 493s 5s/step - loss: 0.0469 - accuracy: 0.9865 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.9423 - val_accuracy: 0.5713 - val_top_k_categorical_accuracy: 1.0000
Epoch 10/10

 1/92 [..............................] - ETA: 6:03 - loss: 0.0151 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 2/92 [..............................] - ETA: 5:50 - loss: 0.0229 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 3/92 [..............................] - ETA: 5:41 - loss: 0.0363 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 4/92 [>.............................] - ETA: 5:37 - loss: 0.0341 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 5/92 [>.............................] - ETA: 5:31 - loss: 0.0328 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 6/92 [>.............................] - ETA: 5:26 - loss: 0.0290 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 7/92 [=>............................] - ETA: 5:21 - loss: 0.0283 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 8/92 [=>............................] - ETA: 5:16 - loss: 0.0271 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
 9/92 [=>............................] - ETA: 5:12 - loss: 0.0261 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
10/92 [==>...........................] - ETA: 5:08 - loss: 0.0251 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
11/92 [==>...........................] - ETA: 5:04 - loss: 0.0237 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
12/92 [==>...........................] - ETA: 5:00 - loss: 0.0223 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
13/92 [===>..........................] - ETA: 4:56 - loss: 0.0212 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
14/92 [===>..........................] - ETA: 4:52 - loss: 0.0215 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
15/92 [===>..........................] - ETA: 4:48 - loss: 0.0230 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
16/92 [====>.........................] - ETA: 4:45 - loss: 0.0225 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
17/92 [====>.........................] - ETA: 4:41 - loss: 0.0238 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
18/92 [====>.........................] - ETA: 4:38 - loss: 0.0245 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000
19/92 [=====>........................] - ETA: 4:34 - loss: 0.0250 - accuracy: 0.9984 - top_k_categorical_accuracy: 1.0000
20/92 [=====>........................] - ETA: 4:31 - loss: 0.0274 - accuracy: 0.9953 - top_k_categorical_accuracy: 1.0000
21/92 [=====>........................] - ETA: 4:27 - loss: 0.0267 - accuracy: 0.9955 - top_k_categorical_accuracy: 1.0000
22/92 [======>.......................] - ETA: 4:24 - loss: 0.0259 - accuracy: 0.9957 - top_k_categorical_accuracy: 1.0000
23/92 [======>.......................] - ETA: 4:20 - loss: 0.0256 - accuracy: 0.9959 - top_k_categorical_accuracy: 1.0000
24/92 [======>.......................] - ETA: 4:17 - loss: 0.0278 - accuracy: 0.9948 - top_k_categorical_accuracy: 1.0000
25/92 [=======>......................] - ETA: 4:13 - loss: 0.0282 - accuracy: 0.9950 - top_k_categorical_accuracy: 1.0000
26/92 [=======>......................] - ETA: 4:09 - loss: 0.0281 - accuracy: 0.9952 - top_k_categorical_accuracy: 1.0000
27/92 [=======>......................] - ETA: 4:09 - loss: 0.0280 - accuracy: 0.9954 - top_k_categorical_accuracy: 1.0000
28/92 [========>.....................] - ETA: 4:08 - loss: 0.0365 - accuracy: 0.9911 - top_k_categorical_accuracy: 1.0000
29/92 [========>.....................] - ETA: 4:07 - loss: 0.0355 - accuracy: 0.9914 - top_k_categorical_accuracy: 1.0000
30/92 [========>.....................] - ETA: 4:04 - loss: 0.0347 - accuracy: 0.9917 - top_k_categorical_accuracy: 1.0000
31/92 [=========>....................] - ETA: 4:03 - loss: 0.0343 - accuracy: 0.9919 - top_k_categorical_accuracy: 1.0000
32/92 [=========>....................] - ETA: 4:01 - loss: 0.0335 - accuracy: 0.9922 - top_k_categorical_accuracy: 1.0000
33/92 [=========>....................] - ETA: 3:56 - loss: 0.0328 - accuracy: 0.9924 - top_k_categorical_accuracy: 1.0000
34/92 [==========>...................] - ETA: 3:55 - loss: 0.0331 - accuracy: 0.9926 - top_k_categorical_accuracy: 1.0000
35/92 [==========>...................] - ETA: 3:53 - loss: 0.0366 - accuracy: 0.9910 - top_k_categorical_accuracy: 1.0000
36/92 [==========>...................] - ETA: 3:50 - loss: 0.0363 - accuracy: 0.9912 - top_k_categorical_accuracy: 1.0000
37/92 [==========>...................] - ETA: 3:48 - loss: 0.0359 - accuracy: 0.9915 - top_k_categorical_accuracy: 1.0000
38/92 [===========>..................] - ETA: 3:46 - loss: 0.0353 - accuracy: 0.9917 - top_k_categorical_accuracy: 1.0000
39/92 [===========>..................] - ETA: 3:43 - loss: 0.0349 - accuracy: 0.9919 - top_k_categorical_accuracy: 1.0000
40/92 [===========>..................] - ETA: 3:40 - loss: 0.0350 - accuracy: 0.9921 - top_k_categorical_accuracy: 1.0000
41/92 [============>.................] - ETA: 3:37 - loss: 0.0343 - accuracy: 0.9923 - top_k_categorical_accuracy: 1.0000
42/92 [============>.................] - ETA: 3:34 - loss: 0.0342 - accuracy: 0.9925 - top_k_categorical_accuracy: 1.0000
43/92 [============>.................] - ETA: 3:31 - loss: 0.0366 - accuracy: 0.9919 - top_k_categorical_accuracy: 1.0000
44/92 [=============>................] - ETA: 3:28 - loss: 0.0360 - accuracy: 0.9921 - top_k_categorical_accuracy: 1.0000
45/92 [=============>................] - ETA: 3:24 - loss: 0.0364 - accuracy: 0.9916 - top_k_categorical_accuracy: 1.0000
46/92 [=============>................] - ETA: 3:20 - loss: 0.0367 - accuracy: 0.9911 - top_k_categorical_accuracy: 1.0000
47/92 [==============>...............] - ETA: 3:15 - loss: 0.0364 - accuracy: 0.9913 - top_k_categorical_accuracy: 1.0000
48/92 [==============>...............] - ETA: 3:10 - loss: 0.0362 - accuracy: 0.9915 - top_k_categorical_accuracy: 1.0000
49/92 [==============>...............] - ETA: 3:05 - loss: 0.0367 - accuracy: 0.9910 - top_k_categorical_accuracy: 1.0000
50/92 [===============>..............] - ETA: 3:01 - loss: 0.0361 - accuracy: 0.9912 - top_k_categorical_accuracy: 1.0000
51/92 [===============>..............] - ETA: 2:56 - loss: 0.0358 - accuracy: 0.9914 - top_k_categorical_accuracy: 1.0000
52/92 [===============>..............] - ETA: 2:52 - loss: 0.0355 - accuracy: 0.9915 - top_k_categorical_accuracy: 1.0000
53/92 [================>.............] - ETA: 2:47 - loss: 0.0352 - accuracy: 0.9917 - top_k_categorical_accuracy: 1.0000
54/92 [================>.............] - ETA: 2:42 - loss: 0.0355 - accuracy: 0.9913 - top_k_categorical_accuracy: 1.0000
55/92 [================>.............] - ETA: 2:38 - loss: 0.0350 - accuracy: 0.9914 - top_k_categorical_accuracy: 1.0000
56/92 [=================>............] - ETA: 2:33 - loss: 0.0349 - accuracy: 0.9916 - top_k_categorical_accuracy: 1.0000
57/92 [=================>............] - ETA: 2:29 - loss: 0.0344 - accuracy: 0.9917 - top_k_categorical_accuracy: 1.0000
58/92 [=================>............] - ETA: 2:24 - loss: 0.0346 - accuracy: 0.9913 - top_k_categorical_accuracy: 1.0000
59/92 [==================>...........] - ETA: 2:20 - loss: 0.0349 - accuracy: 0.9909 - top_k_categorical_accuracy: 1.0000
60/92 [==================>...........] - ETA: 2:16 - loss: 0.0345 - accuracy: 0.9911 - top_k_categorical_accuracy: 1.0000
61/92 [==================>...........] - ETA: 2:11 - loss: 0.0341 - accuracy: 0.9912 - top_k_categorical_accuracy: 1.0000
62/92 [===================>..........] - ETA: 2:07 - loss: 0.0338 - accuracy: 0.9914 - top_k_categorical_accuracy: 1.0000
63/92 [===================>..........] - ETA: 2:03 - loss: 0.0340 - accuracy: 0.9910 - top_k_categorical_accuracy: 1.0000
64/92 [===================>..........] - ETA: 1:58 - loss: 0.0347 - accuracy: 0.9907 - top_k_categorical_accuracy: 1.0000
65/92 [====================>.........] - ETA: 1:54 - loss: 0.0348 - accuracy: 0.9908 - top_k_categorical_accuracy: 1.0000
66/92 [====================>.........] - ETA: 1:50 - loss: 0.0406 - accuracy: 0.9876 - top_k_categorical_accuracy: 1.0000
67/92 [====================>.........] - ETA: 1:45 - loss: 0.0401 - accuracy: 0.9878 - top_k_categorical_accuracy: 1.0000
68/92 [=====================>........] - ETA: 1:41 - loss: 0.0405 - accuracy: 0.9880 - top_k_categorical_accuracy: 1.0000
69/92 [=====================>........] - ETA: 1:37 - loss: 0.0407 - accuracy: 0.9877 - top_k_categorical_accuracy: 1.0000
70/92 [=====================>........] - ETA: 1:33 - loss: 0.0404 - accuracy: 0.9879 - top_k_categorical_accuracy: 1.0000
71/92 [=====================>........] - ETA: 1:29 - loss: 0.0425 - accuracy: 0.9863 - top_k_categorical_accuracy: 1.0000
72/92 [======================>.......] - ETA: 1:24 - loss: 0.0441 - accuracy: 0.9852 - top_k_categorical_accuracy: 1.0000
73/92 [======================>.......] - ETA: 1:20 - loss: 0.0445 - accuracy: 0.9850 - top_k_categorical_accuracy: 1.0000
74/92 [======================>.......] - ETA: 1:16 - loss: 0.0441 - accuracy: 0.9852 - top_k_categorical_accuracy: 1.0000
75/92 [=======================>......] - ETA: 1:12 - loss: 0.0441 - accuracy: 0.9854 - top_k_categorical_accuracy: 1.0000
76/92 [=======================>......] - ETA: 1:08 - loss: 0.0443 - accuracy: 0.9855 - top_k_categorical_accuracy: 1.0000
77/92 [=======================>......] - ETA: 1:04 - loss: 0.0440 - accuracy: 0.9857 - top_k_categorical_accuracy: 1.0000
78/92 [========================>.....] - ETA: 59s - loss: 0.0437 - accuracy: 0.9859 - top_k_categorical_accuracy: 1.0000 
79/92 [========================>.....] - ETA: 55s - loss: 0.0442 - accuracy: 0.9857 - top_k_categorical_accuracy: 1.0000
80/92 [========================>.....] - ETA: 51s - loss: 0.0437 - accuracy: 0.9859 - top_k_categorical_accuracy: 1.0000
81/92 [=========================>....] - ETA: 47s - loss: 0.0446 - accuracy: 0.9857 - top_k_categorical_accuracy: 1.0000
82/92 [=========================>....] - ETA: 43s - loss: 0.0443 - accuracy: 0.9858 - top_k_categorical_accuracy: 1.0000
83/92 [=========================>....] - ETA: 39s - loss: 0.0439 - accuracy: 0.9860 - top_k_categorical_accuracy: 1.0000
84/92 [==========================>...] - ETA: 35s - loss: 0.0440 - accuracy: 0.9862 - top_k_categorical_accuracy: 1.0000
85/92 [==========================>...] - ETA: 31s - loss: 0.0452 - accuracy: 0.9852 - top_k_categorical_accuracy: 1.0000
86/92 [==========================>...] - ETA: 27s - loss: 0.0449 - accuracy: 0.9854 - top_k_categorical_accuracy: 1.0000
87/92 [===========================>..] - ETA: 22s - loss: 0.0447 - accuracy: 0.9856 - top_k_categorical_accuracy: 1.0000
88/92 [===========================>..] - ETA: 18s - loss: 0.0451 - accuracy: 0.9850 - top_k_categorical_accuracy: 1.0000
89/92 [===========================>..] - ETA: 14s - loss: 0.0447 - accuracy: 0.9852 - top_k_categorical_accuracy: 1.0000
90/92 [============================>.] - ETA: 10s - loss: 0.0444 - accuracy: 0.9854 - top_k_categorical_accuracy: 1.0000
91/92 [============================>.] - ETA: 6s - loss: 0.0444 - accuracy: 0.9855 - top_k_categorical_accuracy: 1.0000 
92/92 [============================>.] - ETA: 2s - loss: 0.0446 - accuracy: 0.9853 - top_k_categorical_accuracy: 1.0000
93/92 [==============================] - 512s 6s/step - loss: 0.0443 - accuracy: 0.9855 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.5528 - val_accuracy: 0.6421 - val_top_k_categorical_accuracy: 1.0000
Saving model...
Obtaining training data...
Training Accuracy:
 [0.858058, 0.9467296, 0.97134185, 0.98111933, 0.98415375, 0.98314226, 0.9881996, 0.9858395, 0.98651385, 0.98550236]
Validation Accuracy:
 [0.6531850099563599, 0.6450960636138916, 0.647118330001831, 0.5864509344100952, 0.6865520477294922, 0.5894843339920044, 0.6936299204826355, 0.6026289463043213, 0.5712841153144836, 0.6420626640319824]
Training Loss:
 [0.36609390976858236, 0.1649127697078505, 0.10951965819197737, 0.08193718560105309, 0.06825880715102259, 0.0611042967549728, 0.04889143058378312, 0.052225421358022994, 0.04700424360765731, 0.044432036310499655]
Validation Loss:
 [0.5793126821517944, 0.49260276556015015, 0.38264063000679016, 0.5092004537582397, 0.5898787975311279, 1.0215082168579102, 0.37666913866996765, 0.7404741048812866, 0.9422802329063416, 0.5527586340904236]

 32/990 [..............................] - ETA: 2:38
 64/990 [>.............................] - ETA: 2:35
 96/990 [=>............................] - ETA: 2:29
128/990 [==>...........................] - ETA: 2:23
160/990 [===>..........................] - ETA: 2:19
192/990 [====>.........................] - ETA: 2:07
224/990 [=====>........................] - ETA: 1:58
256/990 [======>.......................] - ETA: 1:49
288/990 [=======>......................] - ETA: 1:42
320/990 [========>.....................] - ETA: 1:35
352/990 [=========>....................] - ETA: 1:30
384/990 [==========>...................] - ETA: 1:24
416/990 [===========>..................] - ETA: 1:19
448/990 [============>.................] - ETA: 1:14
480/990 [=============>................] - ETA: 1:09
512/990 [==============>...............] - ETA: 1:04
544/990 [===============>..............] - ETA: 59s 
576/990 [================>.............] - ETA: 55s
608/990 [=================>............] - ETA: 50s
640/990 [==================>...........] - ETA: 46s
672/990 [===================>..........] - ETA: 41s
704/990 [====================>.........] - ETA: 37s
736/990 [=====================>........] - ETA: 32s
768/990 [======================>.......] - ETA: 28s
800/990 [=======================>......] - ETA: 24s
832/990 [========================>.....] - ETA: 20s
864/990 [=========================>....] - ETA: 16s
896/990 [==========================>...] - ETA: 11s
928/990 [===========================>..] - ETA: 7s 
960/990 [============================>.] - ETA: 3s
990/990 [==============================] - 125s 126ms/step
Using TensorFlow backend.
Printing test results...
loss 0.039118268814953894
acc 0.991919219493866
top 5 acc 1.0
Writing data to .csv file...
Finished writing data!
Starting plotting...
Finished plotting!
Model finished!
